{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 统计学习方法（第一版） 习题解答\n",
    "**撰写人：**胡锐锋-天国之影-Relph  \n",
    "**github地址：**https://github.com/datawhalechina/statistical-learning-method-solutions-manual\n",
    "\n",
    "## 第1章统计学习方法概论-习题\n",
    "\n",
    "### 习题1.1\n",
    "&emsp;&emsp;说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。伯努利模型是定义在取值为0与1的随机变量上的概率分布。假设观测到伯努利模型$n$次独立的数据生成结果，其中$k$次的结果为1，这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**\n",
    "\n",
    "伯努利模型的极大似然估计以及贝叶斯估计中的**统计学习方法三要素**如下：  \n",
    "1. **极大似然估计**  \n",
    "**模型：** $\\mathcal{F}=\\{f|f_p(x)=p^x(1-p)^{(1-x)}\\}$  \n",
    "**策略：** 最大化似然函数  \n",
    "**算法：** $\\displaystyle \\mathop{\\arg\\min}_{p} L(p)= \\mathop{\\arg\\min}_{p} \\binom{n}{k}p^k(1-p)^{(n-k)}$\n",
    "2. **贝叶斯估计**  \n",
    "**模型：** $\\mathcal{F}=\\{f|f_p(x)=p^x(1-p)^{(1-x)}\\}$  \n",
    "**策略：** 求参数期望  \n",
    "**算法：**\n",
    "$$\\begin{aligned}  E_\\pi\\big[p \\big| y_1,\\cdots,y_n\\big]\n",
    "& = {\\int_0^1}p\\pi (p|y_1,\\cdots,y_n) dp \\\\\n",
    "& = {\\int_0^1} p\\frac{f_D(y_1,\\cdots,y_n|p)\\pi(p)}{\\int_{\\Omega}f_D(y_1,\\cdots,y_n|p)\\pi(p)dp}dp \\\\\n",
    "& = {\\int_0^1}\\frac{p^{k+1}(1-p)^{(n-k)}}{\\int_0^1 p^k(1-p)^{(n-k)}dp}dp\n",
    "\\end{aligned}$$\n",
    "\n",
    "**伯努利模型的极大似然估计：**  \n",
    "定义$P(Y=1)$概率为$p$，可得似然函数为：$$L(p)=f_D(y_1,y_2,\\cdots,y_n|\\theta)=\\binom{n}{k}p^k(1-p)^{(n-k)}$$方程两边同时对$p$求导，则：$$\\begin{aligned}\n",
    "0 & = \\binom{n}{k}[kp^{k-1}(1-p)^{(n-k)}-(n-k)p^k(1-p)^{(n-k-1)}]\\\\\n",
    "& = \\binom{n}{k}[p^{(k-1)}(1-p)^{(n-k-1)}(m-kp)]\n",
    "\\end{aligned}$$可解出$p$的值为$p=0,p=1,p=k/n$，显然$\\displaystyle P(Y=1)=p=\\frac{k}{n}$  \n",
    "\n",
    "**伯努利模型的贝叶斯估计：**  \n",
    "定义$P(Y=1)$概率为$p$，$p$在$[0,1]$之间的取值是等概率的，因此先验概率密度函数$\\pi(p) = 1$，可得似然函数为： $$L(p)=f_D(y_1,y_2,\\cdots,y_n|\\theta)=\\binom{n}{k}p^k(1-p)^{(n-k)}$$  \n",
    "根据似然函数和先验概率密度函数，可以求解$p$的条件概率密度函数：$$\\begin{aligned}\\pi(p|y_1,\\cdots,y_n)&=\\frac{f_D(y_1,\\cdots,y_n|p)\\pi(p)}{\\int_{\\Omega}f_D(y_1,\\cdots,y_n|p)\\pi(p)dp}\\\\\n",
    "&=\\frac{p^k(1-p)^{(n-k)}}{\\int_0^1p^k(1-p)^{(n-k)}dp}\\\\\n",
    "&=\\frac{p^k(1-p)^{(n-k)}}{B(k+1,n-k+1)}\n",
    "\\end{aligned}$$所以$p$的期望为：$$\\begin{aligned}\n",
    "E_\\pi[p|y_1,\\cdots,y_n]&={\\int}p\\pi(p|y_1,\\cdots,y_n)dp \\\\\n",
    "& = {\\int_0^1}\\frac{p^{(k+1)}(1-p)^{(n-k)}}{B(k+1,n-k+1)}dp \\\\\n",
    "& = \\frac{B(k+2,n-k+1)}{B(k+1,n-k+1)}\\\\\n",
    "& = \\frac{k+1}{n+2}\n",
    "\\end{aligned}$$\n",
    "$\\therefore \\displaystyle P(Y=1)=\\frac{k+1}{n+2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题1.2\n",
    "&emsp;&emsp;通过经验风险最小化推导极大似然估计。证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**\n",
    "\n",
    "假设模型的条件概率分布是$P_{\\theta}(Y|X)$，现推导当损失函数是对数损失函数时，极大似然估计等价于经验风险最小化。\n",
    "极大似然估计的似然函数为：$$L(\\theta)=\\prod_D P_{\\theta}(Y|X)$$两边取对数：$$\\ln L(\\theta) = \\sum_D \\ln P_{\\theta}(Y|X) \\\\ \n",
    "\\mathop{\\arg \\max}_{\\theta} \\sum_D \\ln P_{\\theta}(Y|X) = \\mathop{\\arg \\min}_{\\theta} \\sum_D (- \\ln P_{\\theta}(Y|X))$$ \n",
    "反之，经验风险最小化等价于极大似然估计，亦可通过经验风险最小化推导极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第2章感知机-习题\n",
    "\n",
    "### 习题2.1\n",
    "&emsp;&emsp;Minsky 与 Papert 指出：感知机因为是线性模型，所以不能表示复杂的函数，如异或 (XOR)。验证感知机为什么不能表示异或。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "\n",
    "对于异或函数XOR，全部的输入与对应的输出如下：  \n",
    "\n",
    "|<div style=\"width:20px\">$x^{(1)}$</div>|<div style=\"width:20px\">$x^{(2)}$</div>|$y$|\n",
    "|:-: | :-: | :-: |  \n",
    "| &nbsp;1 |  &nbsp;1 |-1 | \n",
    "| &nbsp;1 | -1 | &nbsp;1 | \n",
    "|-1 |  &nbsp;1 | &nbsp;1 | \n",
    "|-1 | -1 |-1 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   1   1 -1\n",
       "1   1  -1  1\n",
       "2  -1   1  1\n",
       "3  -1  -1 -1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x1 = [1, 1, -1, -1]\n",
    "x2 = [1, -1, 1, -1]\n",
    "y = [-1, 1, 1, -1]\n",
    "x1 = np.array(x1)\n",
    "x2 = np.array(x2)\n",
    "y = np.array(y)\n",
    "data = np.c_[x1, x2, y]\n",
    "data = pd.DataFrame(data, index=None, columns=['x1', 'x2', 'y'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive = data.loc[data['y'] == 1]\n",
    "negative = data.loc[data['y'] == -1]\n",
    "\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.xticks([-2, -1, 0, 1, 2])\n",
    "plt.yticks([-2, -1, 0, 1, 2])\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.plot(positive['x1'], positive['x2'], \"ro\")\n",
    "plt.plot(negative['x1'], negative['x2'], \"gx\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然感知机无法使用一条直线将两类样本划分，异或问题是线性不可分的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题2.2\n",
    "\n",
    "&emsp;&emsp;模仿例题 2.1，构建从训练数据求解感知机模型的例子。\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[1. 0.]] \n",
      "b: [-2.] \n",
      "\n",
      "[ 1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[3, 3], [4, 3], [1, 1]])\n",
    "y = np.array([1, 1, -1])\n",
    "\n",
    "perceptron_model = Perceptron()\n",
    "perceptron_model.fit(X_train, y)\n",
    "print(\"w:\", perceptron_model.coef_, \"\\nb:\", perceptron_model.intercept_, \"\\n\")\n",
    "\n",
    "result = perceptron_model.predict(X_train)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题2.3\n",
    "证明以下定理：样本集线性可分的充分必要条件是正实例点所构成的凸壳与负实例点所构成的凸壳互不相交。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**首先给出凸壳与线性可分的定义，定义如下：  \n",
    "**凸壳**  \n",
    "**定义1：**设集合$S \\subset R^n$，是由$R^n$中的$k$个点所组成的集合，即$S=\\{x_1,x_2,\\cdots, x_k\\}$。定义$S$的凸壳$\\text{conv}(S)$为：$$\\text{conv}(S) = \\left\\{ x = \\sum_{i=1}^k \\lambda_i x_i \\Big| \\sum_{i=1}^k \\lambda_i=1,\\lambda_i \\geqslant 0, i=1,2,\\cdots, k \\right\\}$$说明：凸壳是一个集合，对于所有可能的$\\lambda_i,i=1,2,\\cdots,k$只要满足$\\displaystyle \\sum_{i=1}^k \\lambda_i = 1$，那么$\\displaystyle x = \\sum_{i=1}^k$即为凸壳中的元素，凸壳可以用二维的图形表示如下：\n",
    "<br/><center>\n",
    "<img style=\"border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);width:400.17px;\" src=\"../images/2-1-Convex-Hull.png\"><br><div style=\"color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #000;padding: 2px;\">图2.1 凸壳</div></center>\n",
    "\n",
    "**线性可分**  \n",
    "**定义2：**给定一个数据集$$T=\\{(x_1,y_1), (x_2,y_2), \\cdots, (x_n,y_n)\\}$$其中$x_i \\in \\mathcal{X}=R_n, y_i \\in \\mathcal{Y} = \\{+1, -1\\}, i=1,2,\\cdots, n$，如果存在某个超平面$S：w \\cdot x + b = 0$，能够将数据集的正实例点和负实例点完全正确划分到超平面的两侧，即对所有的正实例点即$y_i=+1$的实例$i$，有$w \\cdot x_i + b > 0$，对所有的负实例点即$y_i = -1$的实例$i$，有$w \\cdot x_i + b < 0$，则称数据集$T$线性可分，否则称数据集$T$线性不可分。  \n",
    "\n",
    "----\n",
    "\n",
    "**第2步：** 证明必要性：线性可分$\\Rightarrow$凸壳不相交  \n",
    "假设数据集$T$中的正例点集为$S_+$，$S_+$的凸壳为$\\text{conv}(S_+)$，负实例点集为$S_-$，$S_-$的凸壳为$\\text{conv}(S_-)$，若$T$是线性可分的，则存在一个超平面：$$w \\cdot x + b = 0$$能够将$S_+$和$S_-$完全分离。假设对于所有的正例点$x_i$，有：$$w \\cdot x_i + b = \\varepsilon_i$$易知$\\varepsilon_i > 0, i = 1,2,\\cdots,|S_+|。$若$\\text{conv}(S_+)$和$\\text{conv}(S_-)$相交，即存在某个元素$s$，同时满足$s \\in \\text{conv}(S_+)$和$s \\in \\text{conv}(S_-)$。  \n",
    "对于$\\text{conv}(S_+)$中的元素$s^+$有$$w \\cdot s^+ = w \\cdot \\sum_{i=1}^k \\lambda_i x_i = \\sum_{i=1}^k \\lambda_i(\\varepsilon_i - b) = \\sum_{i=1}^k \\lambda_i \\varepsilon_i - b $$因此$\\displaystyle w \\cdot s^+ + b = \\sum_{i=1}^k \\lambda_i \\varepsilon_i > 0$，同理对于$S_-$中的元素$s^-$有$\\displaystyle w \\cdot s^- + b = \\sum_{i=1}^k \\lambda_i \\varepsilon_i < 0$  \n",
    "由于$s \\in \\text{conv}(S_+)$且$s \\in \\text{conv}(S_-)$，则$\\displaystyle w \\cdot s + b = \\sum_{i=1}^k \\lambda_i \\varepsilon_i > 0$且$\\displaystyle w \\cdot s + b = \\sum_{i=1}^k \\lambda_i \\varepsilon_i < 0$，可推出矛盾。  \n",
    "因此，$\\text{conv}(S_+)$ 和$\\text{conv}(S_-)$必不相交。从而必要性得证。  \n",
    "\n",
    "----\n",
    "\n",
    "**第3步：**  \n",
    "证明充分性：凸壳不相交$\\Rightarrow$线性可分  \n",
    "假设数据集$T$中的正例点集为$S_+$，$S_+$的凸壳为$\\text{conv}(S_+)$，负实例点集为$S_-$，$S_-$的凸壳为$\\text{conv}(S_-)$，且$\\text{conv}(S_+)$与$\\text{conv}(S_-)$不相交。  \n",
    "定义两个点$x_1,x_2$的距离为$$\\text{dist}(x_1,x_2) = \\|x_1 - x_2\\|_2 = \\sqrt{(x_1 - x_2)^2}$$  \n",
    "定义$\\text{conv}(S_+)$和$\\text{conv}(S_-)$距离为$$\\text{dist}(\\text{conv}(S_+),\\text{conv}(S_-)) = \\min \\|s_+ - s_-\\|, s_+ \\in \\text{conv}(S_+), s_- \\in \\text{conv}(S_-)$$  \n",
    "设$x_+ \\in \\text{conv}(S_+), x_- \\in \\text{conv}(S_-)$且$\\text{dist}(x_+, x_-) = \\text{dist}(\\text{conv}(S_+),\\text{conv}(S_-))$。则对于任意正例点$x$有$\\text{dist}(x,x_-) \\geqslant \\text{dist}(x_+ , x_-)$。同理，对弈所有的负例点$x$有$\\text{dist}(x,x_+) \\geqslant \\text{dist}(x , x_-)$。  \n",
    "存在超平面$$w \\cdot x + b = 0$$其中$$w = x_+ - x_- \\\\ b = -\\frac{x_+ \\cdot x_+ -  x_- \\cdot x_-}{2}$$  \n",
    "则对于所有的正例点$x$（易知$x \\cdot x_+ + b > 0$，因此若$x_+$属于正例点，则令$x_+ \\neq x$）$$\\begin{aligned}\n",
    "w\\cdot x +b \n",
    "& = (x_+-x_-)\\cdot x-\\frac{x_+ \\cdot x_+ - x_- \\cdot x_-}{2} \\\\\n",
    "& = x_+ \\cdot x -x_- \\cdot x - \\frac{x_+ \\cdot x_+ -x_- \\cdot x_-}{2} \\\\\n",
    "& = \\frac{||x_- - x||_2^2-||x_+ - x||_2^2}{2}\\\\\n",
    "& = \\frac{\\text{dist}(x,x_-)^2-\\text{dist}(x,x_+)^2}{2}\n",
    "\\end{aligned}$$若$\\text{dist}(x,x_-) \\leqslant \\text{dist}(x,x_+)$（即线性不可分），则$\\text{dist}(x,x_-) \\leqslant \\text{dist}(x,x_+) \\leqslant \\text{dist}(x_-,x_+)$，那么$\\text{dist}(\\text{conv}(S_+),\\text{conv}(S_-)) < \\text{dist}(x_+,x_-)$，推出矛盾，因此$\\text{dist}(x,x_-) > \\text{dist}(x,x_+)$，即线性可分，充分性得证。  \n",
    "\n",
    "----\n",
    "\n",
    "**补充：**用反证法证明$\\text{dist}(x,x_-) > \\text{dist}(x,x_+)$  \n",
    "**证明：**假设$\\text{dist}(x,x_-) \\leqslant \\text{dist}(x,x_+)$则存在$$t=\\frac{(x_{-}-x_{+})\\cdot (x-x_{+})}{||x-x_{+}||_2^2}$$令$x' = tx + (1-t) x _+$，则$(x_- - x') \\cdot (x_+ - x) = 0$  \n",
    "易知$t \\leqslant 1$，先证明$t > 0$：  \n",
    "可以将$x, x_+, x_-$看做为空间中的三个不同的点，三条边的长度分别为$\\text{dist}(x, x_+)，\\text{dist}(x, x_-)，\\text{dist}(x_+, x_-)$  \n",
    "如上面可知$\\text{dist}(x,x_+) \\geqslant \\text{dist}(x,x_-) \\geqslant \\text{dist}(x_-,x_+)$  \n",
    "根据三角形的大边对应大角这一特性，很容易可以看出$x_+-x$与$x_+ - x_-$之间的夹角小于90度，因此$t > 0$。  \n",
    "那么$\\text{dist}(x',x_-) < \\text{dist}(x_+,x_-)$，又因为$x'$必在$\\text{conv}(S_+)$内部，故推出矛盾，所以$\\text{dist}(x,x_-) > \\text{dist}(x,x_+)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第3章 k近邻法-习题\n",
    "\n",
    "### 习题3.1\n",
    "&emsp;&emsp;参照图3.1，在二维空间中给出实例点，画出$k$为1和2时的$k$近邻法构成的空间划分，并对其进行比较，体会$k$值选择与模型复杂度及预测准确率的关系。\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap \n",
    "\n",
    "data = np.array([[5, 12, 1],\n",
    "                [6, 21, 0],\n",
    "                [14, 5, 0],\n",
    "                [16, 10, 0],\n",
    "                [13, 19, 0],\n",
    "                [13, 32, 1],\n",
    "                [17, 27, 1],\n",
    "                [18, 24, 1],\n",
    "                [20, 20, 0],\n",
    "                [23, 14, 1],\n",
    "                [23, 25, 1],\n",
    "                [23, 31, 1],\n",
    "                [26, 8, 0],\n",
    "                [30, 17, 1],\n",
    "                [30, 26, 1],\n",
    "                [34, 8, 0],\n",
    "                [34, 19, 1],\n",
    "                [37, 28, 1]])\n",
    "X_train = data[:, 0:2]\n",
    "y_train = data[:, 2]\n",
    "\n",
    "models = (KNeighborsClassifier(n_neighbors=1, n_jobs=-1),\n",
    "          KNeighborsClassifier(n_neighbors=2, n_jobs=-1))\n",
    "models = (clf.fit(X_train, y_train) for clf in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "titles = ('K Neighbors with k=1',\n",
    "          'K Neighbors with k=2')\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = X_train[:, 0], X_train[:, 1]\n",
    "\n",
    "x_min, x_max = X0.min() - 1, X0.max() + 1\n",
    "y_min, y_max = X1.min() - 1, X1.max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.2),\n",
    "                         np.arange(y_min, y_max, 0.2))\n",
    "\n",
    "for clf, title, ax in zip(models, titles, fig.subplots(1, 2).flatten()):    \n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape) \n",
    "    colors = ('red', 'green', 'lightgreen', 'gray', 'cyan')  \n",
    "    cmap = ListedColormap(colors[:len(np.unique(Z))])  \n",
    "    ax.contourf(xx, yy, Z, cmap=cmap, alpha=0.5)\n",
    "    \n",
    "    ax.scatter(X0, X1, c=y_train, s=50, edgecolors='k', cmap=cmap, alpha=0.5)\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题3.2\n",
    "&emsp;&emsp;利用例题3.2构造的$kd$树求点$x=(3,4.5)^T$的最近邻点。\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x点的最近邻点是(2, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "train_data = np.array([(2, 3), (5, 4), (9, 6), (4, 7), (8, 1), (7, 2)])\n",
    "tree = KDTree(train_data, leaf_size=2)\n",
    "dist, ind = tree.query(np.array([(3, 4.5)]), k=1)\n",
    "x1 = train_data[ind[0]][0][0]\n",
    "x2 = train_data[ind[0]][0][1]\n",
    "\n",
    "print(\"x点的最近邻点是({0}, {1})\".format(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题3.3\n",
    "&emsp;&emsp;参照算法3.3，写出输出为$x$的$k$近邻的算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**算法：用kd树的$k$近邻搜索**  \n",
    "输入：已构造的kd树；目标点$x$；    \n",
    "输出：$x$的最近邻    \n",
    "1. 在$kd$树中找出包含目标点$x$的叶结点：从根结点出发，递归地向下访问树。若目标点$x$当前维的坐标小于切分点的坐标，则移动到左子结点，否则移动到右子结点，直到子结点为叶结点为止；  \n",
    "2. 如果“当前$k$近邻点集”元素数量小于$k$或者叶节点距离小于“当前$k$近邻点集”中最远点距离，那么将叶节点插入“当前k近邻点集”；  \n",
    "3. 递归地向上回退，在每个结点进行以下操作：  \n",
    "(a)如果“当前$k$近邻点集”元素数量小于$k$或者当前节点距离小于“当前$k$近邻点集”中最远点距离，那么将该节点插入“当前$k$近邻点集”。  \n",
    "(b)检查另一子结点对应的区域是否与以目标点为球心、以目标点与于“当前$k$近邻点集”中最远点间的距离为半径的超球体相交。如果相交，可能在另一个子结点对应的区域内存在距目标点更近的点，移动到另一个子结点，接着，递归地进行最近邻搜索；如果不相交，向上回退；\n",
    "4. 当回退到根结点时，搜索结束，最后的“当前$k$近邻点集”即为$x$的最近邻点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建kd树，搜索待预测点所属区域\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 建立节点类\n",
    "class Node(namedtuple(\"Node\", \"location left_child right_child\")):\n",
    "    def __repr__(self):\n",
    "        return str(tuple(self))\n",
    "\n",
    "\n",
    "# kd tree类\n",
    "class KdTree():\n",
    "    def __init__(self, k=1):\n",
    "        self.k = k\n",
    "        self.kdtree = None\n",
    "\n",
    "    # 构建kd tree\n",
    "    def _fit(self, X, depth=0):\n",
    "        try:\n",
    "            k = self.k\n",
    "        except IndexError as e:\n",
    "            return None\n",
    "        # 这里可以展开，通过方差选择axis\n",
    "        axis = depth % k\n",
    "        X = X[X[:, axis].argsort()]\n",
    "        median = X.shape[0] // 2\n",
    "        try:\n",
    "            X[median]\n",
    "        except IndexError:\n",
    "            return None\n",
    "        return Node(\n",
    "            location=X[median],\n",
    "            left_child=self._fit(X[:median], depth + 1),\n",
    "            right_child=self._fit(X[median + 1:], depth + 1)\n",
    "        )\n",
    "\n",
    "    def _search(self, point, tree=None, depth=0, best=None):\n",
    "        if tree is None:\n",
    "            return best\n",
    "        k = self.k\n",
    "        # 更新 branch\n",
    "        if point[0][depth % k] < tree.location[depth % k]:\n",
    "            next_branch = tree.left_child\n",
    "        else:\n",
    "            next_branch = tree.right_child\n",
    "        if not next_branch is None:\n",
    "            best = next_branch.location\n",
    "        return self._search(point, tree=next_branch, depth=depth + 1, best=best)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.kdtree = self._fit(X)\n",
    "        return self.kdtree\n",
    "\n",
    "    def predict(self, X):\n",
    "        res = self._search(X, self.kdtree)\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x点的最近邻点是(2, 3)\n"
     ]
    }
   ],
   "source": [
    "KNN = KdTree()\n",
    "X_train = np.array([[2, 3],\n",
    "                    [5, 4],\n",
    "                    [9, 6],\n",
    "                    [4, 7],\n",
    "                    [8, 1],\n",
    "                    [7, 2]])\n",
    "KNN.fit(X_train)\n",
    "X_new = np.array([[3, 4.5]])\n",
    "res = KNN.predict(X_new)\n",
    "\n",
    "x1 = res[0]\n",
    "x2 = res[1]\n",
    "\n",
    "print(\"x点的最近邻点是({0}, {1})\".format(x1, x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第4章朴素贝叶斯法-习题\n",
    "\n",
    "### 习题4.1\n",
    "&emsp;&emsp;用极大似然估计法推出朴素贝叶斯法中的概率估计公式(4.8)及公式 (4.9)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**证明公式(4.8)：$\\displaystyle P(Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}{N}$  \n",
    "由于朴素贝叶斯法假设$Y$是定义在输出空间$\\mathcal{Y}$上的随机变量，因此可以定义$P(Y=c_k)$概率为$p$。  \n",
    "令$\\displaystyle m=\\sum_{i=1}^NI(y_i=c_k)$，得出似然函数：$$L(p)=f_D(y_1,y_2,\\cdots,y_n|\\theta)=\\binom{N}{m}p^m(1-p)^{(N-m)}$$使用微分求极值，两边同时对$p$求微分：$$\\begin{aligned}\n",
    "0 &= \\binom{N}{m}\\left[mp^{(m-1)}(1-p)^{(N-m)}-(N-m)p^m(1-p)^{(N-m-1)}\\right] \\\\\n",
    "& = \\binom{N}{m}\\left[p^{(m-1)}(1-p)^{(N-m-1)}(m-Np)\\right]\n",
    "\\end{aligned}$$可求解得到$\\displaystyle p=0,p=1,p=\\frac{m}{N}$  \n",
    "显然$\\displaystyle P(Y=c_k)=p=\\frac{m}{N}=\\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}{N}$，公式(4.8)得证。\n",
    "\n",
    "----\n",
    "\n",
    "**第2步：**证明公式(4.9)：$\\displaystyle P(X^{(j)}=a_{jl}|Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}$  \n",
    "令$P(X^{(j)}=a_{jl}|Y=c_k)=p$，令$\\displaystyle m=\\sum_{i=1}^N I(y_i=c_k), q=\\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)$，得出似然函数：$$L(p)=\\binom{m}{q}p^q(i-p)^{m-q}$$使用微分求极值，两边同时对$p$求微分：$$\\begin{aligned}\n",
    "0 &= \\binom{m}{q}\\left[qp^{(q-1)}(1-p)^{(m-q)}-(m-q)p^q(1-p)^{(m-q-1)}\\right] \\\\\n",
    "& = \\binom{m}{q}\\left[p^{(q-1)}(1-p)^{(m-q-1)}(q-mp)\\right]\n",
    "\\end{aligned}$$可求解得到$\\displaystyle p=0,p=1,p=\\frac{q}{m}$  \n",
    "显然$\\displaystyle P(X^{(j)}=a_{jl}|Y=c_k)=p=\\frac{q}{m}=\\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k)}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k)}$，公式(4.9)得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题4.2\n",
    "&emsp;&emsp;用贝叶斯估计法推出朴素贝叶斯法中的慨率估计公式(4.10)及公式(4.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**证明公式(4.11)：$\\displaystyle P(Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N+K \\lambda}$  \n",
    "加入先验概率，在没有任何信息的情况下，可以假设先验概率为均匀概率（即每个事件的概率是相同的）。  \n",
    "可得$\\displaystyle p=\\frac{1}{K} \\Leftrightarrow pK-1=0\\quad(1)$  \n",
    "根据习题4.1得出先验概率的极大似然估计是$\\displaystyle pN - \\sum_{i=1}^N I(y_i=c_k) = 0\\quad(2)$  \n",
    "存在参数$\\lambda$使得$(1) \\cdot \\lambda + (2) = 0$  \n",
    "所以有$$\\lambda(pK-1) + pN - \\sum_{i=1}^N I(y_i=c_k) = 0$$可得$\\displaystyle P(Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N+K \\lambda}$，公式(4.11)得证。  \n",
    "\n",
    "----\n",
    "\n",
    "**第2步：**证明公式(4.10)：$\\displaystyle P_{\\lambda}(X^{(j)}=a_{jl} | Y = c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k) + \\lambda}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + S_j \\lambda}$   \n",
    "根据第1步，可同理得到$$\n",
    "P(Y=c_k, x^{(j)}=a_{j l})=\\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k, x_i^{(j)}=a_{jl})+\\lambda}{N+K S_j \\lambda}$$  \n",
    "$$\\begin{aligned} \n",
    "P(x^{(j)}=a_{jl} | Y=c_k)\n",
    "&= \\frac{P(Y=c_k, x^{(j)}=a_{j l})}{P(y_i=c_k)} \\\\\n",
    "&= \\frac{\\displaystyle \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k, x_i^{(j)}=a_{jl})+\\lambda}{N+K S_j \\lambda}}{\\displaystyle \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N+K \\lambda}} \\\\\n",
    "&= (\\lambda可以任意取值，于是取\\lambda = S_j \\lambda) \\\\\n",
    "&= \\frac{\\displaystyle \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k, x_i^{(j)}=a_{jl})+\\lambda}{N+K S_j \\lambda}}{\\displaystyle \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda}{N+K S_j \\lambda}} \\\\ \n",
    "&= \\frac{\\displaystyle \\sum_{i=1}^N I(y_i=c_k, x_i^{(j)}=a_{jl})+\\lambda}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + \\lambda} (其中\\lambda = S_j \\lambda)\\\\\n",
    "&= \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl},y_i=c_k) + \\lambda}{\\displaystyle \\sum_{i=1}^N I(y_i=c_k) + S_j \\lambda}\n",
    "\\end{aligned} $$  \n",
    "公式(4.11)得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第5章决策树-习题\n",
    "\n",
    "### 习题5.1\n",
    "根据表5.1所给的训练数据集，利用信息增益比（C4.5算法）生成决策树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "\n",
    "表5.1 贷款申请样本数据表  \n",
    "\n",
    "ID | 年龄 | 有工作 | 有自己的房子 | 信贷情况 | 类别\n",
    ":-: | :-: | :-: | :-: | :-: | :-: \n",
    "1 | 青年 | 否 | 否 | 一般 | 否\n",
    "2 | 青年 | 否 | 否 | 好 | 否\n",
    "3 | 青年 | 是 | 否 | 好 | 是\n",
    "4 | 青年 | 是 | 是 | 一般 | 是\n",
    "5 | 青年 | 否 | 否 | 一般 | 否\n",
    "6 | 中年 | 否 | 否 | 一般 | 否\n",
    "7 | 中年 | 否 | 否 | 好 | 否\n",
    "8 | 中年 | 是 | 是 | 好 | 是\n",
    "9 | 中年 | 否 | 是 | 非常好 | 是\n",
    "10 | 中年 | 否 | 是 | 非常好 | 是\n",
    "11 | 老年 | 否 | 是 | 非常好 | 是\n",
    "12 | 老年 | 否 | 是 | 好 | 是\n",
    "13 | 老年 | 是 | 否 | 好 | 是\n",
    "14 | 老年 | 是 | 否 | 非常好 | 是\n",
    "15 | 老年 | 否 | 否 | 一般 | 否"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "features = [\"年龄\", \"有工作\", \"有自己的房子\", \"信贷情况\"]\n",
    "X_train = pd.DataFrame([\n",
    "    [\"青年\", \"否\", \"否\", \"一般\"],\n",
    "    [\"青年\", \"否\", \"否\", \"好\"],\n",
    "    [\"青年\", \"是\", \"否\", \"好\"],\n",
    "    [\"青年\", \"是\", \"是\", \"一般\"],\n",
    "    [\"青年\", \"否\", \"否\", \"一般\"],\n",
    "    [\"中年\", \"否\", \"否\", \"一般\"],\n",
    "    [\"中年\", \"否\", \"否\", \"好\"],\n",
    "    [\"中年\", \"是\", \"是\", \"好\"],\n",
    "    [\"中年\", \"否\", \"是\", \"非常好\"],\n",
    "    [\"中年\", \"否\", \"是\", \"非常好\"],\n",
    "    [\"老年\", \"否\", \"是\", \"非常好\"],\n",
    "    [\"老年\", \"否\", \"是\", \"好\"],\n",
    "    [\"老年\", \"是\", \"否\", \"好\"],\n",
    "    [\"老年\", \"是\", \"否\", \"非常好\"],\n",
    "    [\"老年\", \"否\", \"否\", \"一般\"]\n",
    "])\n",
    "y_train = pd.DataFrame([\"否\", \"否\", \"是\", \"是\", \"否\", \n",
    "                        \"否\", \"否\", \"是\", \"是\", \"是\", \n",
    "                        \"是\", \"是\", \"是\", \"是\", \"否\"])\n",
    "# 数据预处理\n",
    "le_x = preprocessing.LabelEncoder()\n",
    "le_x.fit(np.unique(X_train))\n",
    "X_train = X_train.apply(le_x.transform)\n",
    "le_y = preprocessing.LabelEncoder()\n",
    "le_y.fit(np.unique(y_train))\n",
    "y_train = y_train.apply(le_y.transform)\n",
    "# 调用sklearn.DT建立训练模型\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"277pt\" height=\"314pt\"\r\n",
       " viewBox=\"0.00 0.00 277.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 273,-310 273,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#bddef6\" stroke=\"black\" d=\"M210,-306C210,-306 115,-306 115,-306 109,-306 103,-300 103,-294 103,-294 103,-235 103,-235 103,-229 109,-223 115,-223 115,-223 210,-223 210,-223 216,-223 222,-229 222,-235 222,-235 222,-294 222,-294 222,-300 216,-306 210,-306\"/>\r\n",
       "<text text-anchor=\"start\" x=\"111\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">有自己的房子 ≤ 3.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"129\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\r\n",
       "<text text-anchor=\"start\" x=\"119\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\r\n",
       "<text text-anchor=\"start\" x=\"122\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 9]</text>\r\n",
       "<text text-anchor=\"start\" x=\"133.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#f2c09c\" stroke=\"black\" d=\"M142,-187C142,-187 69,-187 69,-187 63,-187 57,-181 57,-175 57,-175 57,-116 57,-116 57,-110 63,-104 69,-104 69,-104 142,-104 142,-104 148,-104 154,-110 154,-116 154,-116 154,-175 154,-175 154,-181 148,-187 142,-187\"/>\r\n",
       "<text text-anchor=\"start\" x=\"70.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">有工作 ≤ 3.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"68\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\r\n",
       "<text text-anchor=\"start\" x=\"66\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\r\n",
       "<text text-anchor=\"start\" x=\"65\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 3]</text>\r\n",
       "<text text-anchor=\"start\" x=\"76.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.724,-222.907C138.524,-214.286 134.044,-205.09 129.701,-196.175\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"132.767,-194.478 125.241,-187.021 126.474,-197.544 132.767,-194.478\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"117.091\" y=\"-206.955\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M257,-179.5C257,-179.5 184,-179.5 184,-179.5 178,-179.5 172,-173.5 172,-167.5 172,-167.5 172,-123.5 172,-123.5 172,-117.5 178,-111.5 184,-111.5 184,-111.5 257,-111.5 257,-111.5 263,-111.5 269,-117.5 269,-123.5 269,-123.5 269,-167.5 269,-167.5 269,-173.5 263,-179.5 257,-179.5\"/>\r\n",
       "<text text-anchor=\"start\" x=\"191.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"181\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\r\n",
       "<text text-anchor=\"start\" x=\"180\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\r\n",
       "<text text-anchor=\"start\" x=\"191.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>0&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M182.623,-222.907C188.093,-211.873 194.029,-199.898 199.544,-188.773\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202.753,-190.181 204.058,-179.667 196.481,-187.072 202.753,-190.181\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"212.045\" y=\"-199.657\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#e58139\" stroke=\"black\" d=\"M85,-68C85,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,-0 12,-0 12,-0 85,-0 85,-0 91,-0 97,-6 97,-12 97,-12 97,-56 97,-56 97,-62 91,-68 85,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"19.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"9\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 0]</text>\r\n",
       "<text text-anchor=\"start\" x=\"19.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 0</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M84.2753,-103.726C79.7649,-95.0615 74.9939,-85.8962 70.4568,-77.1802\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"73.556,-75.5537 65.834,-68.2996 67.3469,-78.7859 73.556,-75.5537\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M200,-68C200,-68 127,-68 127,-68 121,-68 115,-62 115,-56 115,-56 115,-12 115,-12 115,-6 121,-0 127,-0 127,-0 200,-0 200,-0 206,-0 212,-6 212,-12 212,-12 212,-56 212,-56 212,-62 206,-68 200,-68\"/>\r\n",
       "<text text-anchor=\"start\" x=\"134.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"start\" x=\"124\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\r\n",
       "<text text-anchor=\"start\" x=\"123\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\r\n",
       "<text text-anchor=\"start\" x=\"134.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = 1</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>1&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.097,-103.726C131.687,-95.0615 136.541,-85.8962 141.158,-77.1802\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"144.274,-78.7748 145.862,-68.2996 138.088,-75.4982 144.274,-78.7748\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1b1d1e0af60>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可视化\n",
    "dot_data = tree.export_graphviz(model_tree, out_file=None,\n",
    "                                    feature_names=features,\n",
    "                                    class_names=[str(k) for k in np.unique(y_train)],\n",
    "                                    filled=True, rounded=True,\n",
    "                                    special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题5.2\n",
    "&emsp;&emsp;已知如表5.2所示的训练数据，试用平方误差损失准则生成一个二叉回归树。  \n",
    "表5.2 训练数据表  \n",
    "\n",
    "| $x_i$ | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |  \n",
    "| - | - | - | - | - | - | - | - | - | - | - |  \n",
    "| $y_i$ | 4.50 | 4.75 | 4.91 | 5.34 | 5.80 | 7.05 | 7.90 | 8.23 | 8.70 | 9.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "&emsp;&emsp;决策树的生成就是递归地构建二叉决策树的过程，对回归树用平方误差最小化准则，对分类树用基尼指数（Gini index）最小化准则，进行特征选择，生成二叉树。  \n",
    "> 算法5.5（最小二乘回归树生成算法）  \n",
    "输入：训练数据集$D$  \n",
    "输出：回归树$f(x)$  \n",
    "在训练数据集所在的输入空间中，递归地将每个区域划分为两个子区域并决定每个子区域上的输出值，构建二叉决策树；  \n",
    "(1)选择最优切分变量$j$与切分点$s$，求解$$\\min_{j,s} \\left[ \\min_{c_1} \\sum_{x_i \\in R_1(j,s)} (y_i - c_1)^2 + \\min_{c_2} \\sum_{x_i \\in R_2(j,s)} (y_i - c_2)^2\\right]$$遍历变量$j$，对固定的切分变量$j$扫描切分点$s$，选择使得上式达到最小值的对$(j,s)$  \n",
    "(2)用选定的对$(j,s)$划分区域并决定相应的输出值：$$R_1(j,s)=\\{x|x^{(j)}\\leqslant s\\}, R_2(j,s)=\\{x|x^{(j)} > s\\} \\\\ \n",
    "\\hat{c_m} = \\frac{1}{N_m} \\sum_{x_i \\in R_m(j,s)} y_i, x \\in R_m, m=1,2 $$\n",
    "(3)继续对两个子区域调用步骤(1),(2)，直至满足停止条件  \n",
    "(4)将输入空间划分为$M$个区域$R_1,R_2,\\cdots,R_M$，生成决策树：$$f(x)=\\sum_{m=1}^M \\hat{c_m} I(x \\in R_m)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class LeastSqRTree:\n",
    "    def __init__(self, train_X, y, epsilon):\n",
    "        # 训练集特征值\n",
    "        self.x = train_X\n",
    "        # 类别\n",
    "        self.y = y\n",
    "        # 特征总数\n",
    "        self.feature_count = train_X.shape[1]\n",
    "        # 损失阈值\n",
    "        self.epsilon = epsilon\n",
    "        # 回归树\n",
    "        self.tree = None\n",
    "\n",
    "    def _fit(self, x, y, feature_count, epsilon):\n",
    "        # 选择最优切分点变量j与切分点s\n",
    "        (j, s, minval, c1, c2) = self._divide(x, y, feature_count)\n",
    "        # 初始化树\n",
    "        tree = {\"feature\": j, \"value\": x[s, j], \"left\": None, \"right\": None}\n",
    "        if minval < self.epsilon or len(y[np.where(x[:, j] <= x[s, j])]) <= 1:\n",
    "            tree[\"left\"] = c1\n",
    "        else:\n",
    "            tree[\"left\"] = self._fit(x[np.where(x[:, j] <= x[s, j])], \n",
    "                                     y[np.where(x[:, j] <= x[s, j])],\n",
    "                                     self.feature_count,\n",
    "                                     self.epsilon)\n",
    "        if minval < self.epsilon or len(y[np.where(x[:, j] > s)]) <= 1:\n",
    "            tree[\"right\"] = c2\n",
    "        else:\n",
    "            tree[\"right\"] = self._fit(x[np.where(x[:, j] > x[s, j])], \n",
    "                                      y[np.where(x[:, j] > x[s, j])],\n",
    "                                      self.feature_count,\n",
    "                                      self.epsilon)\n",
    "        return tree\n",
    "\n",
    "    def fit(self):\n",
    "        self.tree = self._fit(self.x, self.y, self.feature_count, self.epsilon)\n",
    "\n",
    "    @staticmethod\n",
    "    def _divide(x, y, feature_count):\n",
    "        # 初始化损失误差\n",
    "        cost = np.zeros((feature_count, len(x)))\n",
    "        # 公式5.21\n",
    "        for i in range(feature_count):\n",
    "            for k in range(len(x)):\n",
    "                # k行i列的特征值\n",
    "                value = x[k, i]\n",
    "                y1 = y[np.where(x[:, i] <= value)]\n",
    "                c1 = np.mean(y1)\n",
    "                y2 = y[np.where(x[:, i] > value)]\n",
    "                c2 = np.mean(y2)\n",
    "                y1[:] = y1[:] - c1\n",
    "                y2[:] = y2[:] - c2\n",
    "                cost[i, k] = np.sum(y1 * y1) + np.sum(y2 * y2)\n",
    "        # 选取最优损失误差点\n",
    "        cost_index = np.where(cost == np.min(cost))\n",
    "        # 选取第几个特征值\n",
    "        j = cost_index[0][0]\n",
    "        # 选取特征值的切分点\n",
    "        s = cost_index[1][0]\n",
    "        # 求两个区域的均值c1,c2\n",
    "        c1 = np.mean(y[np.where(x[:, j] <= x[s, j])])\n",
    "        c2 = np.mean(y[np.where(x[:, j] > x[s, j])])\n",
    "        return j, s, cost[cost_index], c1, c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Learning_Projects\\MyPythonProjects\\statistical-learning-method-camp\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "E:\\Learning_Projects\\MyPythonProjects\\statistical-learning-method-camp\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'feature': 0,\n",
       " 'value': 5,\n",
       " 'left': {'feature': 0, 'value': 3, 'left': 4.72, 'right': 5.57},\n",
       " 'right': {'feature': 0,\n",
       "  'value': 7,\n",
       "  'left': {'feature': 0, 'value': 6, 'left': 7.05, 'right': 7.9},\n",
       "  'right': {'feature': 0, 'value': 8, 'left': 8.23, 'right': 8.85}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]).T\n",
    "y = np.array([4.50, 4.75, 4.91, 5.34, 5.80, 7.05, 7.90, 8.23, 8.70, 9.00])\n",
    "\n",
    "model_tree = LeastSqRTree(train_X, y, .2)\n",
    "model_tree.fit()\n",
    "model_tree.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上面程序的输出，可得到用平方误差损失准则生成一个二叉回归树：$$f(x)=\\begin{cases}\n",
    "4.72 & x \\le 3\\\\\n",
    "5.57 & 3 < x \\le 5\\\\\n",
    "7.05 & 5 < x \\le 6\\\\\n",
    "7.9 & 6 < x \\le 7 \\\\\n",
    "8.23 & 7 < x \\le 8\\\\\n",
    "8.85 & x > 8\\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题5.3\n",
    "\n",
    "&emsp;&emsp;证明 CART 剪枝算法中，当$\\alpha$确定时，存在唯一的最小子树$T_{\\alpha}$使损失函数$C_{\\alpha}(T)$最小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**内部节点是否剪枝只与以该节点为根节点的子树有关。  \n",
    "剪枝过程：  \n",
    "计算子树的损失函数：$$C_{\\alpha}(T)=C(T)+\\alpha$$其中，$\\displaystyle C(T) = \\sum_{t=1}^{|T|}N_t (1 - \\sum_{k=1}^K (\\frac{N_{tk}}{N_t})^2)$，$|T|$是叶结点个数，$K$是类别个数。  \n",
    "有剪枝前子树$T_0$，剪枝后子树$T_1$，满足$C_{\\alpha}(T_1) \\leqslant C_{\\alpha}(T_0)$则进行剪枝。 \n",
    "\n",
    "----\n",
    "\n",
    "**第2步（反证法）：**假设当$\\alpha$确定时，存在两颗子树$T_1,T_2$都使得损失函数$C_{\\alpha}$最小。  \n",
    "第1种情况：假设被剪枝的子树在同一边，易知其中一个子树会由另一个子树剪枝而得到，故不可能存在两个最优子树，原结论得证。  \n",
    "第2种情况：假设被剪枝的子树不在同一边，易知被剪枝掉的子树都可以使损失函数$C_{\\alpha}$最小，故两颗子树都可以继续剪枝，故不可能存在两个最优子树，原结论得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题5.4\n",
    "\n",
    "&emsp;&emsp;证明 CART 剪枝算法中求出的子树序列$\\{T_0,T_1,\\cdots,T_n\\}$分别是区间$\\alpha \\in [\\alpha_i,\\alpha_{i+1})$的最优子树$T_{\\alpha}$，这里$i=0,1,\\cdots,n,0=\\alpha_0 < \\alpha_1 < \\cdots, \\alpha_n < +\\infty$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "原结论可以表述为：将$\\alpha$从小增大，$0=\\alpha_0<\\alpha_1<\\cdots<\\alpha_n < +\\infty$，在每个区间$[\\alpha_i,\\alpha_{i+1})$中，子树$T_i$是这个区间里最优的。  \n",
    "**第1步：**易证，当$\\alpha=0$时，整棵树$T_0$是最优的，当$\\alpha \\rightarrow +\\infty$时，根结点组成的单结点树（即$T_n$）是最优的。\n",
    "\n",
    "----\n",
    "\n",
    "**第2步：**  \n",
    "&emsp;&emsp;由于每次剪枝剪的都是某个内部结点的子结点，也就是将某个内部结点的所有子结点回退到这个内部结点里，并将这个内部结点作为叶子结点。因此在计算整体的损失函数时，这个内部结点以外的值都没变，只有这个内部结点的局部损失函数改变了，因此本来需要计算全局的损失函数，但现在只需要计算内部结点剪枝前和剪枝后的损失函数。  \n",
    "从整体树$T_0$开始剪枝，对$T_0$的任意内部结点$t$    \n",
    "剪枝前的状态：有$|T_t|$个叶子结点，预测误差是$C(T_t)$  \n",
    "剪枝后的状态：只有本身一个叶子结点，预测误差是$C(t)$\n",
    "因此剪枝前的以$t$结点为根结点的子树的损失函数是$$C_{\\alpha}(T_t) = C(T_t) + \\alpha|T_t|$$剪枝后的损失函数是$$C_{\\alpha}(t) = C(t) + \\alpha$$易得，一定存在一个$\\alpha$使得$C_{\\alpha}(T_t) = C_{\\alpha}(t)$，这个值为$$\\alpha=\\frac{C(t)-C(T_t)}{|T_t|-1}$$可知，找到$\\alpha$即找到了子结点$t$，即完成了剪枝，得到最优子树$T_1$  \n",
    "根据书中第73页，采用以下公式计算剪枝后整体损失函数减少的程度：$$g(t)=\\frac{C(t)-C(T_t)}{|T_t|-1}$$在$T_0$中剪去$g(t)$最小的$T_t$，将得到的子树作为$T_1$，同时将最小的$g(t)$设为$\\alpha_1$，$T_1$为区间$[\\alpha_1,\\alpha_2)$的最优子树。  \n",
    "依次类推，子树$T_i$是区间$[\\alpha_i,\\alpha_{i+1})$里最优的，原结论得证。\n",
    "\n",
    "----\n",
    "\n",
    "**参考文献：**  \n",
    "1. MrTriste：https://blog.csdn.net/wjc1182511338/article/details/76793164\n",
    "2. http://www.pianshen.com/article/1752163397/\n",
    "\n",
    "----\n",
    "\n",
    "**讨论：**为什么$\\alpha$要取最小的$g(t)$呢？  \n",
    "<br/><center>\n",
    "<img style=\"border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);width: 354px;\" src=\"../images/5-1-min-g(t).png\"><br><div style=\"color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #000;padding: 2px;\">图5.1 最小的$g(t)$</div></center>   \n",
    "&emsp;&emsp;以图中两个点为例，结点1和结点2，$g(t)_2$大于$g(t)_1$，假设在所有结点中$g(t)_1$最小，$g(t)_2$最大，两种选择方法：当选择最大值$g(t)_2$，即结点2进行剪枝，但此时结点1的剪枝前的误差大于剪枝后的误差，即如果不剪枝，误差变大，依次类推，对其它所有的结点的$g(t)$都是如此，从而造成整体的累计误差更大。反之，如果选择最小值$g(t)_1$，即结点1进行剪枝，则其余结点不剪的误差要小于剪枝后的误差，不剪枝为好，且整体的误差最小。从而以最小$g(t)$剪枝获得的子树是该$\\alpha$值下的最优子树。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第6章Logistic回归与最大熵模型-习题\n",
    "\n",
    "### 习题6.1\n",
    "&emsp;&emsp;确认Logistic分布属于指数分布族。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**  \n",
    "首先给出指数分布族的定义：  \n",
    "对于随机变量$x$，在给定参数$\\eta$下，其概率分别满足如下形式：$$p(x|\\eta)=h(x)g(\\eta)\\exp(\\eta^Tu(x))$$我们称之为**指数分布族**。  \n",
    "其中：  \n",
    "$x$：可以是标量或者向量，可以是离散值也可以是连续值  \n",
    "$\\eta$：自然参数  \n",
    "$g(\\eta)$：归一化系数  \n",
    "$h(x),u(x)$：$x$的某个函数  \n",
    "\n",
    "----\n",
    "\n",
    "**第2步：**证明伯努利分布属于指数分布族  \n",
    "伯努利分布：$\\varphi$是$y=1$的概率，即$P(Y=1)=\\varphi$  \n",
    "$\\begin{aligned}\n",
    "P(y|\\varphi) \n",
    "&= \\varphi^y (1-\\varphi)^{(1-y)} \\\\\n",
    "&= (1-\\varphi) \\varphi^y (1-\\varphi)^{(-y)} \\\\\n",
    "&= (1-\\varphi) (\\frac{\\varphi}{1-\\varphi})^y \\\\\n",
    "&= (1-\\varphi) \\exp\\left(y \\ln \\frac{\\varphi}{1-\\varphi} \\right) \\\\\n",
    "&= \\frac{1}{1+e^\\eta} \\exp (\\eta y)\n",
    "\\end{aligned}$  \n",
    "其中，$\\displaystyle \\eta=\\ln \\frac{\\varphi}{1-\\varphi} \\Leftrightarrow \\varphi = \\frac{1}{1+e^{-\\eta}}$  \n",
    "将$y$替换成$x$，可得$\\displaystyle P(x|\\eta) = \\frac{1}{1+e^\\eta} \\exp (\\eta x)$\n",
    "对比可知，伯努利分布属于指数分布族，其中$\\displaystyle h(x) = 1, g(\\eta)= \\frac{1}{1+e^\\eta}, u(x)=x$  \n",
    "\n",
    "----\n",
    "\n",
    "**第3步：**  \n",
    "广义线性模型（GLM）必须满足三个假设：\n",
    "1. $y | x;\\theta \\sim ExponentialFamily(\\eta)$，即假设预测变量$y$在给定$x$，以$\\theta$为参数的条件概率下，属于以$\\eta$作为自然参数的指数分布族；  \n",
    "2. 给定$x$，求解出以$x$为条件的$T(y)$的期望$E[T(y)|x]$，即算法输出为$h(x)=E[T(y)|x]$  \n",
    "3. 满足$\\eta=\\theta^T x$，即自然参数和输入特征向量$x$之间线性相关，关系由$\\theta$决定，仅当$\\eta$是实数时才有意义，若$\\eta$是一个向量，则$\\eta_i=\\theta_i^T x$\n",
    "\n",
    "----\n",
    "\n",
    "**第4步：**推导伯努利分布的GLM  \n",
    "已知伯努利分布属于指数分布族，对给定的$x,\\eta$，求解期望：$$\\begin{aligned}\n",
    "h_{\\theta}(x) \n",
    "&= E[y|x;\\theta] \\\\\n",
    "&= 1 \\cdot p(y=1)+ 0 \\cdot p(y=0) \\\\\n",
    "&= \\varphi \\\\\n",
    "&= \\frac{1}{1+e^{-\\eta}} \\\\\n",
    "&= \\frac{1}{1+e^{-\\theta^T x}}\n",
    "\\end{aligned}$$可得到Logistic回归算法，故Logistic分布属于指数分布族，得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题6.2\n",
    "&emsp;&emsp;写出Logistic回归模型学习的梯度下降算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "对于Logistic模型：$$P(Y=1 | x)=\\frac{\\exp (w \\cdot x+b)}{1+\\exp (w \\cdot x+b)} \\\\ P(Y=0 | x)=\\frac{1}{1+\\exp (w \\cdot x+b)}\n",
    "$$对数似然函数为：$\\displaystyle L(w)=\\sum_{i=1}^N \\left[y_i (w \\cdot x_i)-\\log \\left(1+\\exp (w \\cdot x_i)\\right)\\right]$  \n",
    "似然函数求偏导，可得$\\displaystyle \\frac{\\partial L(w)}{\\partial w^{(j)}}=\\sum_{i=1}^N\\left[x_i^{(j)} \\cdot y_i-\\frac{\\exp (w \\cdot x_i) \\cdot x_i^{(j)}}{1+\\exp (w \\cdot x_i)}\\right]$  \n",
    "梯度函数为：$\\displaystyle \\nabla L(w)=\\left[\\frac{\\partial L(w)}{\\partial w^{(0)}}, \\cdots, \\frac{\\partial L(w)}{\\partial w^{(m)}}\\right]$  \n",
    "Logistic回归模型学习的梯度下降算法：  \n",
    "(1) 取初始值$x^{(0)} \\in R$，置$k=0$  \n",
    "(2) 计算$f(x^{(k)})$  \n",
    "(3) 计算梯度$g_k=g(x^{(k)})$，当$\\|g_k\\| < \\varepsilon$时，停止迭代，令$x^* = x^{(k)}$；否则，求$\\lambda_k$，使得$\\displaystyle f(x^{(k)}+\\lambda_k g_k) = \\max_{\\lambda \\geqslant 0}f(x^{(k)}+\\lambda g_k)$  \n",
    "(4) 置$x^{(k+1)}=x^{(k)}+\\lambda_k g_k$，计算$f(x^{(k+1)})$，当$\\|f(x^{(k+1)}) - f(x^{(k)})\\| < \\varepsilon$或 $\\|x^{(k+1)} - x^{(k)}\\| < \\varepsilon$时，停止迭代，令$x^* = x^{(k+1)}$  \n",
    "(5) 否则，置$k=k+1$，转(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pylab import mpl\n",
    "\n",
    "# 图像显示中文\n",
    "mpl.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learn_rate=0.1, max_iter=10000, tol=1e-2):\n",
    "        self.learn_rate = learn_rate  # 学习率\n",
    "        self.max_iter = max_iter  # 迭代次数\n",
    "        self.tol = tol  # 迭代停止阈值\n",
    "        self.w = None  # 权重\n",
    "\n",
    "    def preprocessing(self, X):\n",
    "        \"\"\"将原始X末尾加上一列，该列数值全部为1\"\"\"\n",
    "        row = X.shape[0]\n",
    "        y = np.ones(row).reshape(row, 1)\n",
    "        X_prepro = np.hstack((X, y))\n",
    "        return X_prepro\n",
    "\n",
    "    def sigmod(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        X = self.preprocessing(X_train)\n",
    "        y = y_train.T\n",
    "        # 初始化权重w\n",
    "        self.w = np.array([[0] * X.shape[1]], dtype=np.float)\n",
    "        k = 0\n",
    "        for loop in range(self.max_iter):\n",
    "            # 计算梯度\n",
    "            z = np.dot(X, self.w.T)\n",
    "            grad = X * (y - self.sigmod(z))\n",
    "            grad = grad.sum(axis=0)\n",
    "            # 利用梯度的绝对值作为迭代中止的条件\n",
    "            if (np.abs(grad) <= self.tol).all():\n",
    "                break\n",
    "            else:\n",
    "                # 更新权重w 梯度上升——求极大值\n",
    "                self.w += self.learn_rate * grad\n",
    "                k += 1\n",
    "        print(\"迭代次数：{}次\".format(k))\n",
    "        print(\"最终梯度：{}\".format(grad))\n",
    "        print(\"最终权重：{}\".format(self.w[0]))\n",
    "\n",
    "    def predict(self, x):\n",
    "        p = self.sigmod(np.dot(self.preprocessing(x), self.w.T))\n",
    "        print(\"Y=1的概率被估计为：{:.2%}\".format(p[0][0]))  # 调用score时，注释掉\n",
    "        p[np.where(p > 0.5)] = 1\n",
    "        p[np.where(p < 0.5)] = 0\n",
    "        return p\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_c = self.predict(X)\n",
    "        error_rate = np.sum(np.abs(y_c - y.T)) / y_c.shape[0]\n",
    "        return 1 - error_rate\n",
    "\n",
    "    def draw(self, X, y):\n",
    "        # 分离正负实例点\n",
    "        y = y[0]\n",
    "        X_po = X[np.where(y == 1)]\n",
    "        X_ne = X[np.where(y == 0)]\n",
    "        # 绘制数据集散点图\n",
    "        ax = plt.axes(projection='3d')\n",
    "        x_1 = X_po[0, :]\n",
    "        y_1 = X_po[1, :]\n",
    "        z_1 = X_po[2, :]\n",
    "        x_2 = X_ne[0, :]\n",
    "        y_2 = X_ne[1, :]\n",
    "        z_2 = X_ne[2, :]\n",
    "        ax.scatter(x_1, y_1, z_1, c=\"r\", label=\"正实例\")\n",
    "        ax.scatter(x_2, y_2, z_2, c=\"b\", label=\"负实例\")\n",
    "        ax.legend(loc='best')\n",
    "        # 绘制p=0.5的区分平面\n",
    "        x = np.linspace(-3, 3, 3)\n",
    "        y = np.linspace(-3, 3, 3)\n",
    "        x_3, y_3 = np.meshgrid(x, y)\n",
    "        a, b, c, d = self.w[0]\n",
    "        z_3 = -(a * x_3 + b * y_3 + d) / c\n",
    "        ax.plot_surface(x_3, y_3, z_3, alpha=0.5)  # 调节透明度\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数：3232次\n",
      "最终梯度：[ 0.00144779  0.00046133  0.00490279 -0.00999848]\n",
      "最终权重：[  2.96908597   1.60115396   5.04477438 -13.43744079]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练数据集\n",
    "X_train = np.array([[3, 3, 3], [4, 3, 2], \n",
    "                    [2, 1, 2], [1, 1, 1], \n",
    "                    [-1, 0, 1], [2, -2, 1]])\n",
    "y_train = np.array([[1, 1, 1, 0, 0, 0]])\n",
    "# 构建实例，进行训练\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "clf.draw(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题6.3\n",
    "&emsp;&emsp;写出最大熵模型学习的DFP算法。（关于一般的DFP算法参见附录B）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**  \n",
    "最大熵模型为：$$\n",
    "\\begin{array}{cl}\n",
    "{\\max } & {H(p)=-\\sum_{x, y} P(x) P(y | x) \\log P(y | x)} \\\\ \n",
    "{\\text {st.}} &\n",
    "{E_p(f_i)-E_{\\hat{p}}(f_i)=0, \\quad i=1,2, \\cdots,n} \\\\ \n",
    "& {\\sum_y P(y | x)=1}\n",
    "\\end{array}$$引入拉格朗日乘子，定义拉格朗日函数：$$\n",
    "L(P, w)=\\sum_{xy} P(x) P(y | x) \\log P(y | x)+w_0 \\left(1-\\sum_y P(y | x)\\right) \\\\\n",
    "+\\sum_{i=1} w_i\\left(\\sum_{xy} P(x, y) f_i(x, y)-\\sum_{xy} P(x, y) P(y | x) f_i(x, y)\\right)$$\n",
    "最优化原始问题为：$$\\min_{P \\in C} \\max_{w} L(P,w)$$对偶问题为：$$\\max_{w} \\min_{P \\in C} L(P,w)$$令$$\\Psi(w) = \\min_{P \\in C} L(P,w) = L(P_w, w)$$$\\Psi(w)$称为对偶函数，同时，其解记作$$P_w = \\mathop{\\arg \\min}_{P \\in C} L(P,w) = P_w(y|x)$$求$L(P,w)$对$P(y|x)$的偏导数，并令偏导数等于0，解得：$$P_w(y | x)=\\frac{1}{Z_w(x)} \\exp \\left(\\sum_{i=1}^n w_i f_i (x, y)\\right)$$其中：$$Z_w(x)=\\sum_y \\exp \\left(\\sum_{i=1}^n w_i f_i(x, y)\\right)$$则最大熵模型目标函数表示为$$\\varphi(w)=\\min_{w \\in R_n} \\Psi(w) = \\sum_{x} P(x) \\log \\sum_{y} \\exp \\left(\\sum_{i=1}^{n} w_{i} f_{i}(x, y)\\right)-\\sum_{x, y} P(x, y) \\sum_{i=1}^{n} w_{i} f_{i}(x, y)$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第2步：**  \n",
    "DFP的$G_{k+1}$的迭代公式为：$$G_{k+1}=G_k+\\frac{\\delta_k \\delta_k^T}{\\delta_k^T y_k}-\\frac{G_k y_k y_k^T G_k}{y_k^T G_k y_k}$$  \n",
    "**最大熵模型的DFP算法：**   \n",
    "输入：目标函数$\\varphi(w)$，梯度$g(w) = \\nabla g(w)$，精度要求$\\varepsilon$；  \n",
    "输出：$\\varphi(w)$的极小值点$w^*$  \n",
    "(1)选定初始点$w^{(0)}$，取$G_0$为正定对称矩阵，置$k=0$  \n",
    "(2)计算$g_k=g(w^{(k)})$，若$\\|g_k\\| < \\varepsilon$，则停止计算，得近似解$w^*=w^{(k)}$，否则转(3)  \n",
    "(3)置$p_k=-G_kg_k$  \n",
    "(4)一维搜索：求$\\lambda_k$使得$$\\varphi\\left(w^{(k)}+\\lambda_k P_k\\right)=\\min _{\\lambda \\geqslant 0} \\varphi\\left(w^{(k)}+\\lambda P_{k}\\right)$$(5)置$w^{(k+1)}=w^{(k)}+\\lambda_k p_k$  \n",
    "(6)计算$g_{k+1}=g(w^{(k+1)})$，若$\\|g_{k+1}\\| < \\varepsilon$，则停止计算，得近似解$w^*=w^{(k+1)}$；否则，按照迭代式算出$G_{k+1}$  \n",
    "(7)置$k=k+1$，转(3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第7章支持向量机-习题\n",
    "\n",
    "### 习题7.1\n",
    "&emsp;&emsp;比较感知机的对偶形式与线性可分支持向景机的对偶形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**感知机算法的原始形式：**  \n",
    "给定一个训练数据集$$T=\\{(x_1,y_1),(x_2,y_2),\\cdots,(x_N,y_N)\\}$$其中，$x_i \\in \\mathcal{X} = R^n, y_i \\in \\mathcal{Y}=\\{-1,1\\}, i=1,2,\\cdots,N$，求参数$w,b$，使其为以下损失函数极小化问题的解：$$\\min_{w,b} L(w,b)=-\\sum_{x_i \\in M} y_i(w \\cdot x_i + b)$$其中M为误分类点的集合。  \n",
    "上式等价于：$$\\min_{w,b} L(w,b)=\\sum_{i=1}^N (-y_i(w \\cdot x_i + b))_+$$\n",
    "\n",
    "----\n",
    "\n",
    "**补充：** 合页损失函数$$L(y(w \\cdot x + b)) = [1-y(w \\cdot x + b)]_+$$下标“+”表示以下取正数的函数。$$[z]_+ = \\left\\{\\begin{array}{ll} z, & z>0 \\\\\n",
    "0, & z \\leqslant 0 \n",
    "\\end{array} \\right.$$当样本点$(x_i,y_i)$被正确分类且函数间隔（确信度）$y_i(w \\cdot x_i + b)$大于1时，损失是0，否则损失是$1-y_i(w \\cdot x_i + b)$。\n",
    "\n",
    "----\n",
    "\n",
    "**感知机算法的对偶形式：**  \n",
    "$w,b$表示为$\\langle x_i,y_i \\rangle$的线性组合的形式，求其系数（线性组合的系数）$\\displaystyle w=\\sum_{i=1}^N \\alpha_i y_i x_i, b=\\sum_{i=1}^N \\alpha_i y_i$，满足：$$\n",
    "\\min_{w,b} L(w,b) = \\min_{\\alpha_i} L(\\alpha_i) = \\sum_{i=1}^N (-y_i (\\sum_{j=1}^N \\alpha_j y_j x_j \\cdot x_i + \\sum_{j=1}^N \\alpha_j y_j))_+$$  \n",
    "\n",
    "**线性可分支持向量机的原始问题：**  \n",
    "$$\\begin{array}{cl} \n",
    "\\displaystyle \\min_{w,b} & \\displaystyle \\frac{1}{2} \\|w\\|^2 \\\\\n",
    "\\text{s.t.} & y_i(w \\cdot x_i + b) -1 \\geqslant 0, i=1,2,\\cdots,N\n",
    "\\end{array}$$  \n",
    "\n",
    "**线性可分支持向量机的对偶问题：**  \n",
    "$$\\begin{array}{cl} \n",
    "\\displaystyle \\max_{\\alpha} & \\displaystyle -\\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j (x_i \\cdot x_j) + \\sum_{i=1}^N \n",
    "alpha_i \\\\\n",
    "\\text{s.t.} & \\displaystyle \\sum_{i=1}^N \\alpha_i y+i = 0 \\\\\n",
    "& \\alpha \\geqslant 0, i=1,2,\\cdots,N\n",
    "\\end{array}$$根据书上**定理7.2**，可得$\\displaystyle w^*=\\sum_{i=1}^N \\alpha_i^* y_j x_i, b^*=y_i-\\sum_{i=1}^N \\alpha^* y_i (x_i \\cdot x_j)$，可以看出$w,b$实质上也是将其表示为$\\langle x_i, x_j\\rangle$的线性组合形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题7.2\n",
    "\n",
    "&emsp;&emsp;已知正例点$x_1=(1,2)^T,x_2=(2,3)^T,x_3=(3,3)^T$，负例点$x_4=(2,1)^T,x_5=(3,2)^T$，试求最大间隔分离平面和分类决策函数，并在图中挂出分离超平面、间隔边界及支持向量。  \n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[-1.  2.]]\n",
      "b = [-2.]\n",
      "support vectors = [[3. 2.]\n",
      " [1. 2.]\n",
      " [3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 加载数据\n",
    "X = [[1, 2], [2, 3], [3, 3], [2, 1], [3, 2]]\n",
    "y = [1, 1, 1, -1, -1]\n",
    "\n",
    "# 训练SVM模型\n",
    "clf = SVC(kernel='linear', C=10000)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(\"w =\", clf.coef_)\n",
    "print(\"b =\", clf.intercept_)\n",
    "print(\"support vectors =\", clf.support_vectors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**最大间隔分离超平面：**$-x^{(1)}+2x^{(2)}-2=0$  \n",
    "**分类决策函数：**$f(x)=\\text{sign}(-x^{(1)}+2x^{(2)}-2)$  \n",
    "**支持向量：**$x_1=(3,2)^T,x_2=(1,2)^T, x_3=(3,3)^T$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 绘制数据点\n",
    "color_seq = ['red' if v==1 else 'blue' for v in y]\n",
    "plt.scatter([i[0] for i in X], [i[1] for i in X], c=color_seq)\n",
    "# 得到x轴的所有点\n",
    "xaxis = np.linspace(0, 3.5)\n",
    "w = clf.coef_[0]\n",
    "# 计算斜率\n",
    "a = -w[0] / w[1]\n",
    "# 得到分离超平面\n",
    "y_sep = a * xaxis - (clf.intercept_[0]) / w[1]\n",
    "# 下边界超平面\n",
    "b = clf.support_vectors_[0]\n",
    "yy_down = a * xaxis + (b[1] - a * b[0])\n",
    "# 上边界超平面\n",
    "b = clf.support_vectors_[-1]\n",
    "yy_up = a * xaxis + (b[1] - a * b[0])\n",
    "# 绘制超平面\n",
    "plt.plot(xaxis, y_sep, 'k-')\n",
    "plt.plot(xaxis, yy_down, 'k--')\n",
    "plt.plot(xaxis, yy_up, 'k--')\n",
    "# 绘制支持向量\n",
    "plt.xlabel('$x^{(1)}$')\n",
    "plt.ylabel('$x^{(2)}$')\n",
    "plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], \n",
    "            s=150, facecolors='none', edgecolors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题7.3\n",
    "\n",
    "&emsp;&emsp;线性支持向量机还可以定义为以下形式：$$\\begin{array}{cl} \n",
    "\\displaystyle \\min_{w,b,\\xi} & \\displaystyle \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^N \\xi_i^2 \\\\\n",
    "\\text{s.t.} & y_i(w \\cdot x_i + b) \\geqslant 1 - \\xi_i, i=1,2,\\cdots, N \\\\\n",
    "& \\xi_i \\geqslant 0, i=1,2,\\cdots, N\n",
    "\\end{array}$$试求其对偶形式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "根据支持向量机的对偶算法，得到对偶形式，由于不能消去变量$\\xi_i$的部分，所以拉格朗日因子也包含$\\beta_i$。  \n",
    "拉格朗日函数为：$$L(w,b,\\xi, \\alpha, \\beta) = \\frac{1}{2} \\|w\\|^2 + C \\sum_{i=1}^N \\xi_i^2 + \\sum_{i=1}^N \\alpha_i - \\sum_{i=1}^N \\alpha_i \\xi_i - \\sum_{i=1}^N \\alpha_i y_i (w \\cdot x_i + b) - \\sum_{i=1}^N \\beta_i \\xi_i$$  \n",
    "分别求$w,b,\\xi$的偏导数：$$\\left \\{ \\begin{array}{l}\n",
    "\\displaystyle \\nabla_w L  = w - \\sum_{i=1}^N \\alpha_i y_i x_i = 0 \\\\ \n",
    "\\displaystyle \\nabla_b L  =  -\\sum_{i=1}^N \\alpha_i y_i = 0 \\\\\n",
    "\\nabla_{\\xi} L  = 2C \\xi_i - \\alpha_i - \\beta_i = 0 \n",
    "\\end{array} \\right.$$化简可得：$$\\left \\{ \\begin{array}{l}\n",
    "\\displaystyle w = \\sum_{i=1}^N \\alpha_i y_i x_i = 0 \\\\ \n",
    "\\displaystyle \\sum_{i=1}^N \\alpha_i y_i = 0 \\\\\n",
    "2C \\xi_i - \\alpha_i - \\beta_i = 0 \n",
    "\\end{array} \\right.$$  \n",
    "可解得：$$\n",
    "L=-\\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j (x_i \\cdot x_{j})+\\sum_{i=1}^N \\alpha_i-\\frac{1}{4C}\\sum_{i=1}^N(\\alpha_i+\\beta_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题7.4\n",
    "\n",
    "&emsp;&emsp;证明内积的正整数幂函数：$$K(x,z)=(x\\cdot z)^p$$是正定核函数，这里$p$是正整数，$ x,z\\in R^n$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "根据书中第121页定理7.5可知，如果需要证明$K(x,z)$是正定核函数，即证明$K(x,z)$对应的Gram矩阵$K=\\left[ K(x_i,x_j) \\right]_{m \\times m}$是半正定矩阵。  \n",
    "对任意$c_1,c_2,\\cdots,c_m \\in \\mathbf{R}$，有$$\\begin{aligned} \n",
    "\\sum_{i,j=1}^m c_i c_j K(x_i,x_j) \n",
    "&= \\sum_{i,j=1}^m c_i c_j (x_i \\cdot x_j)^p \\\\\n",
    "&= \\left(\\sum_{i=1}^m c_i x_i \\right)\\left(\\sum_{j=1}^m c_i x_j \\right)(x_i \\cdot x_j)^{p-1} \\\\\n",
    "&= \\Bigg\\|\\left( \\sum_{i=1}^m c_i x_i \\right)\\Bigg\\|^2 (x_i \\cdot x_j)^{p-1}\n",
    "\\end{aligned}$$\n",
    "$\\because p$是正整数，$p \\geqslant 1$  \n",
    "$\\therefore p-1 \\geqslant 0 \\Rightarrow (x_i \\cdot x_j)^{p-1} \\geqslant 0$  \n",
    "故$\\displaystyle \\sum_{i,j=1}^m c_i c_j K(x_i,x_j) \\geqslant 0$，即Gram矩阵是半正定矩阵。  \n",
    "根据定理7.5，可得$K(x,z)$是正定核函数，得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第8章提升方法-习题\n",
    "\n",
    "### 习题8.1\n",
    "&emsp;&emsp;某公司招聘职员考查身体、业务能力、发展潜力这3项。身体分为合格1、不合格0两级，业务能力和发展潜力分为上1、中2、下3三级分类为合格1 、不合格-1两类。已知10个人的数据，如下表所示。假设弱分类器为决策树桩。试用AdaBoost算法学习一个强分类器。  \n",
    "\n",
    "应聘人员情况数据表\n",
    "\n",
    "&emsp;&emsp;|1|2|3|4|5|6|7|8|9|10\n",
    "-|-|-|-|-|-|-|-|-|-|-\n",
    "身体|0|0|1|1|1|0|1|1|1|0\n",
    "业务|1|3|2|1|2|1|1|1|3|2\n",
    "潜力|3|1|2|3|3|2|2|1|1|1\n",
    "分类|-1|-1|-1|-1|-1|-1|1|1|-1|-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 加载训练数据\n",
    "X = np.array([[0, 1, 3],\n",
    "              [0, 3, 1],\n",
    "              [1, 2, 2],\n",
    "              [1, 1, 3],\n",
    "              [1, 2, 3],\n",
    "              [0, 1, 2],\n",
    "              [1, 1, 2],\n",
    "              [1, 1, 1],\n",
    "              [1, 3, 1],\n",
    "              [0, 2, 1]\n",
    "              ])\n",
    "y = np.array([-1, -1, -1, -1, -1, -1, 1, 1, -1, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoostClassifier分类器实现：**\n",
    "\n",
    "采用sklearn的AdaBoostClassifier分类器直接求解，由于AdaBoostClassifier分类器默认采用CART决策树弱分类器，故不需要设置base_estimator参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "预测输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "预测正确率：100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X, y)\n",
    "y_predict = clf.predict(X)\n",
    "score = clf.score(X, y)\n",
    "print(\"原始输出:\", y)\n",
    "print(\"预测输出:\", y_predict)\n",
    "print(\"预测正确率：{:.2%}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**自编程实现：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自编程求解例8.1\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, X, y, tol=0.05, max_iter=10):\n",
    "        # 训练数据 实例\n",
    "        self.X = X\n",
    "        # 训练数据 标签\n",
    "        self.y = y\n",
    "        # 训练中止条件 right_rate>self.tol\n",
    "        self.tol = tol\n",
    "        # 最大迭代次数\n",
    "        self.max_iter = max_iter\n",
    "        # 初始化样本权重w\n",
    "        self.w = np.full((X.shape[0]), 1 / X.shape[0])\n",
    "        self.G = []  # 弱分类器\n",
    "\n",
    "    def build_stump(self):\n",
    "        \"\"\"\n",
    "        以带权重的分类误差最小为目标，选择最佳分类阈值\n",
    "        best_stump['dim'] 合适的特征所在维度\n",
    "        best_stump['thresh']  合适特征的阈值\n",
    "        best_stump['ineq']  树桩分类的标识lt,rt\n",
    "        \"\"\"\n",
    "        m, n = np.shape(self.X)\n",
    "        # 分类误差\n",
    "        e_min = np.inf\n",
    "        # 小于分类阈值的样本属于的标签类别\n",
    "        sign = None\n",
    "        # 最优分类树桩\n",
    "        best_stump = {}\n",
    "        for i in range(n):\n",
    "            range_min = self.X[:, i].min()  # 求每一种特征的最大最小值\n",
    "            range_max = self.X[:, i].max()\n",
    "            step_size = (range_max - range_min) / n\n",
    "            for j in range(-1, int(n) + 1):\n",
    "                thresh_val = range_min + j * step_size\n",
    "                # 计算左子树和右子树的误差\n",
    "                for inequal in ['lt', 'rt']:\n",
    "                    predict_vals = self.base_estimator(self.X, i, thresh_val, inequal)\n",
    "                    err_arr = np.array(np.ones(m))\n",
    "                    err_arr[predict_vals.T == self.y.T] = 0\n",
    "                    weighted_error = np.dot(self.w, err_arr)\n",
    "                    if weighted_error < e_min:\n",
    "                        e_min = weighted_error\n",
    "                        sign = predict_vals\n",
    "                        best_stump['dim'] = i\n",
    "                        best_stump['thresh'] = thresh_val\n",
    "                        best_stump['ineq'] = inequal\n",
    "        return best_stump, sign, e_min\n",
    "\n",
    "    def updata_w(self, alpha, predict):\n",
    "        \"\"\"\n",
    "        更新样本权重w\n",
    "        \"\"\"\n",
    "        # 以下2行根据公式8.4 8.5 更新样本权重\n",
    "        P = self.w * np.exp(-alpha * self.y * predict)\n",
    "        self.w = P / P.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def base_estimator(X, dimen, threshVal, threshIneq):\n",
    "        \"\"\"\n",
    "        计算单个弱分类器（决策树桩）预测输出\n",
    "        \"\"\"\n",
    "        ret_array = np.ones(np.shape(X)[0])  # 预测矩阵\n",
    "        # 左叶子 ，整个矩阵的样本进行比较赋值\n",
    "        if threshIneq == 'lt':\n",
    "            ret_array[X[:, dimen] <= threshVal] = -1.0\n",
    "        else:\n",
    "            ret_array[X[:, dimen] > threshVal] = -1.0\n",
    "        return ret_array\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        对训练数据进行学习\n",
    "        \"\"\"\n",
    "        G = 0\n",
    "        for i in range(self.max_iter):\n",
    "            best_stump, sign, error = self.build_stump()  # 获取当前迭代最佳分类阈值\n",
    "            alpha = 1 / 2 * np.log((1 - error) / error)  # 计算本轮弱分类器的系数\n",
    "            # 弱分类器权重\n",
    "            best_stump['alpha'] = alpha\n",
    "            # 保存弱分类器\n",
    "            self.G.append(best_stump)\n",
    "            # 以下3行计算当前总分类器（之前所有弱分类器加权和）分类效率\n",
    "            G += alpha * sign\n",
    "            y_predict = np.sign(G)\n",
    "            error_rate = np.sum(np.abs(y_predict - self.y)) / 2 / self.y.shape[0]\n",
    "            if error_rate < self.tol:  # 满足中止条件 则跳出循环\n",
    "                print(\"迭代次数:\", i + 1)\n",
    "                break\n",
    "            else:\n",
    "                self.updata_w(alpha, y_predict)  # 若不满足，更新权重，继续迭代\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        对新数据进行预测\n",
    "        \"\"\"\n",
    "        m = np.shape(X)[0]\n",
    "        G = np.zeros(m)\n",
    "        for i in range(len(self.G)):\n",
    "            stump = self.G[i]\n",
    "            # 遍历每一个弱分类器，进行加权\n",
    "            _G = self.base_estimator(X, stump['dim'], stump['thresh'], stump['ineq'])\n",
    "            alpha = stump['alpha']\n",
    "            G += alpha * _G\n",
    "        y_predict = np.sign(G)\n",
    "        return y_predict.astype(int)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"对训练效果进行评价\"\"\"\n",
    "        y_predict = self.predict(X)\n",
    "        error_rate = np.sum(np.abs(y_predict - y)) / 2 / y.shape[0]\n",
    "        return 1 - error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 8\n",
      "原始输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "预测输出: [-1 -1 -1 -1 -1 -1  1  1 -1 -1]\n",
      "预测正确率：100.00%\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoost(X, y)\n",
    "clf.fit()\n",
    "y_predict = clf.predict(X)\n",
    "score = clf.score(X, y)\n",
    "print(\"原始输出:\", y)\n",
    "print(\"预测输出:\", y_predict)\n",
    "print(\"预测正确率：{:.2%}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题8.2\n",
    "&emsp;&emsp;比较支持向量机、 AdaBoost 、Logistic回归模型的学习策略与算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "- **支持向量机**  \n",
    "学习策略：极小化正则化合页损失，软间隔最大化；  \n",
    "学习算法：序列最小最优化算法（SMO）  \n",
    "- **AdaBoost**  \n",
    "学习策略：极小化加法模型指数损失；  \n",
    "学习算法：前向分步加法算法  \n",
    "- **Logistic回归**  \n",
    "学习策略：极大似然估计，正则化的极大似然估计；  \n",
    "学习算法：改进的迭代尺度算法，梯度下降，拟牛顿法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第9章EM算法及其推广-习题\n",
    "### 习题9.1\n",
    "\n",
    "&emsp;&emsp;如例9.1的三硬币模型，假设观测数据不变，试选择不同的处置，例如，$\\pi^{(0)}=0.46,p^{(0)}=0.55,q^{(0)}=0.67$，求模型参数为$\\theta=(\\pi,p,q)$的极大似然估计。  \n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class EM:\n",
    "    def __init__(self, prob):\n",
    "        self.pro_A, self.pro_B, self.pro_C = prob\n",
    "        \n",
    "    def pmf(self, i):\n",
    "        pro_1 = self.pro_A * math.pow(self.pro_B, data[i]) \\\n",
    "            * math.pow((1-self.pro_B), 1-data[i])\n",
    "        pro_2 = (1 - self.pro_A) * math.pow(self.pro_C, data[i]) \\\n",
    "            * math.pow((1-self.pro_C), 1-data[i])\n",
    "        return pro_1 / (pro_1 + pro_2)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        print('init prob:{}, {}, {}'.format(self.pro_A, self.pro_B, self.pro_C))\n",
    "        count = len(data)\n",
    "        theta = 1\n",
    "        d = 0\n",
    "        while(theta > 0.00001):\n",
    "            # 迭代阻塞\n",
    "            _pmf = [self.pmf(k) for k in range(count)]\n",
    "            pro_A = 1/ count * sum(_pmf)\n",
    "            pro_B = sum([_pmf[k]*data[k] for k in range(count)]) \\\n",
    "            / sum([_pmf[k] for k in range(count)])\n",
    "            pro_C = sum([(1-_pmf[k])*data[k] for k in range(count)]) \\\n",
    "            / sum([(1-_pmf[k]) for k in range(count)])\n",
    "            d += 1\n",
    "            print('{}  pro_a:{:.4f}, pro_b:{:.4f}, pro_c:{:.4f}'.format(d, pro_A, pro_B, pro_C))\n",
    "            theta = abs(self.pro_A-pro_A) + abs(self.pro_B-pro_B) + abs(self.pro_C-pro_C)\n",
    "            self.pro_A = pro_A\n",
    "            self.pro_B = pro_B\n",
    "            self.pro_C = pro_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init prob:0.46, 0.55, 0.67\n",
      "1  pro_a:0.4619, pro_b:0.5346, pro_c:0.6561\n",
      "2  pro_a:0.4619, pro_b:0.5346, pro_c:0.6561\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "data=[1,1,0,1,0,0,1,0,1,1]\n",
    "\n",
    "em = EM(prob=[0.46, 0.55, 0.67])\n",
    "f = em.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见通过两次迭代，参数已经收敛，三个硬币的概率分别为0.4619，0.5346，0.6561"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题9.2\n",
    "证明引理9.2。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **引理9.2：**若$\\tilde{P}_{\\theta}(Z)=P(Z | Y, \\theta)$，则$$F(\\tilde{P}, \\theta)=\\log P(Y|\\theta)$$\n",
    "\n",
    "**证明：**  \n",
    "由$F$函数的定义（**定义9.3**）可得：$$F(\\tilde{P}, \\theta)=E_{\\tilde{P}}[\\log P(Y,Z|\\theta)] + H(\\tilde{P})$$其中，$H(\\tilde{P})=-E_{\\tilde{P}} \\log \\tilde{P}(Z)$  \n",
    "$\\begin{aligned}\n",
    "\\therefore F(\\tilde{P}, \\theta) \n",
    "&= E_{\\tilde{P}}[\\log P(Y,Z|\\theta)] -E_{\\tilde{P}} \\log \\tilde{P}(Z) \\\\\n",
    "&= \\sum_Z \\log P(Y,Z|\\theta) \\tilde{P}_{\\theta}(Z) - \\sum_Z \\log \\tilde{P}(Z) \\cdot \\tilde{P}(Z) \\\\\n",
    "&= \\sum_Z \\log P(Y,Z|\\theta) P(Z|Y,\\theta) -  \\sum_Z \\log P(Z|Y,\\theta) \\cdot P(Z|Y,\\theta) \\\\\n",
    "&= \\sum_Z P(Z|Y,\\theta) \\left[ \\log P(Y,Z|\\theta) - \\log P(Z|Y,\\theta) \\right] \\\\\n",
    "&= \\sum_Z P(Z|Y,\\theta) \\log \\frac{P(Y,Z|\\theta)}{P(Z|Y,\\theta)} \\\\\n",
    "&= \\sum_Z P(Z|Y,\\theta) \\log P(Y|\\theta) \\\\\n",
    "&= \\log P(Y|\\theta) \\sum_Z P(Z|Y,\\theta)\n",
    "\\end{aligned}$  \n",
    "$\\displaystyle \\because \\sum_Z \\tilde{P}_{\\theta}(Z) = P(Z|Y, \\theta) = 1$  \n",
    "$\\therefore F(\\tilde{P}, \\theta) = \\log P(Y|\\theta)$，引理9.2得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题9.3\n",
    "已知观测数据  \n",
    "-67，-48，6，8，14，16，23，24，28，29，41，49，56，60，75  \n",
    "试估计两个分量的高斯混合模型的5个参数。\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels = [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 初始化观测数据\n",
    "data=np.array([-67, -48, 6, 8, 14, 16, 23, 24, 28, 29, 41, 49, 56, 60, 75]).reshape(-1, 1)\n",
    "\n",
    "# 聚类\n",
    "gmmModel = GaussianMixture(n_components=2)\n",
    "gmmModel.fit(data)\n",
    "labels = gmmModel.predict(data)\n",
    "print(\"labels =\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means = [[-57.51107027  32.98489643]]\n",
      "covariances = [[ 90.24987882 429.45764867]]\n",
      "weights =  [[0.13317238 0.86682762]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(labels)):\n",
    "    if labels[i] == 0:\n",
    "        plt.scatter(i, data.take(i), s=15, c='red')\n",
    "    elif labels[i] == 1:\n",
    "        plt.scatter(i, data.take(i), s=15, c='blue')\n",
    "plt.title('Gaussian Mixture Model')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "print(\"means =\", gmmModel.means_.reshape(1, -1))\n",
    "print(\"covariances =\", gmmModel.covariances_.reshape(1, -1))\n",
    "print(\"weights = \", gmmModel.weights_.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题9.4\n",
    "&emsp;&emsp;EM算法可以用到朴素贝叶斯法的非监督学习，试写出其算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：** \n",
    "> **EM算法的一般化：**  \n",
    "**E步骤：**根据参数初始化或上一次迭代的模型参数来计算出隐变量的后验概率，其实就是隐变量的期望。作为隐变量的现估计值：$$w_j^{(i)}=Q_{i}(z^{(i)}=j) := p(z^{(i)}=j | x^{(i)} ; \\theta)$$\n",
    "**M步骤：**将似然函数最大化以获得新的参数值：$$\n",
    "\\theta :=\\arg \\max_{\\theta} \\sum_i \\sum_{z^{(i)}} Q_i (z^{(i)}) \\log \\frac{p(x^{(i)}, z^{(i)} ; \\theta)}{Q_i (z^{(i)})}\n",
    "$$  \n",
    "\n",
    "使用NBMM（朴素贝叶斯的混合模型）中的$\\phi_z,\\phi_{j|z^{(i)}=1},\\phi_{j|z^{(i)}=0}$参数替换一般化的EM算法中的$\\theta$参数，然后依次求解$w_j^{(i)}$与$\\phi_z,\\phi_{j|z^{(i)}=1},\\phi_{j|z^{(i)}=0}$参数的更新问题。  \n",
    "**NBMM的EM算法：**  \n",
    "**E步骤：**  \n",
    "$$w_j^{(i)}:=P\\left(z^{(i)}=1 | x^{(i)} ; \\phi_z, \\phi_{j | z^{(i)}=1}, \\phi_{j | z^{(i)}=0}\\right)$$**M步骤：**$$\n",
    "\\phi_{j | z^{(i)}=1} :=\\frac{\\displaystyle \\sum_{i=1}^{m} w^{(i)} I(x_{j}^{(i)}=1)}{\\displaystyle \\sum_{i=1}^{m} w^{(i)}} \\\\ \n",
    "\\phi_{j | z^{(i)}=0}:= \\frac{\\displaystyle  \\sum_{i=1}^{m}\\left(1-w^{(i)}\\right) I(x_{j}^{(i)}=1)}{ \\displaystyle \\sum_{i=1}^{m}\\left(1-w^{(i)}\\right)} \\\\ \n",
    "\\phi_{z^{(i)}} :=\\frac{\\displaystyle \\sum_{i=1}^{m} w^{(i)}}{m} \n",
    "$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第10章隐马尔可夫模型-习题\n",
    "\n",
    "### 习题10.1\n",
    "&emsp;&emsp;给定盒子和球组成的隐马尔可夫模型$\\lambda=(A,B,\\pi)$，其中，$$A=\\left[\\begin{array}{ccc}0.5&0.2&0.3\\\\0.3&0.5&0.2\\\\0.2&0.3&0.5\\end{array}\\right], \\quad B=\\left[\\begin{array}{cc}0.5&0.5\\\\0.4&0.6\\\\0.7&0.3\\end{array}\\right], \\quad \\pi=(0.2,0.4,0.4)^T$$设$T=4,O=(红,白,红,白)$，试用后向算法计算$P(O|\\lambda)$。\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HiddenMarkov:\n",
    "    def __init__(self):\n",
    "        self.alphas = None\n",
    "        self.forward_P = None\n",
    "        self.betas = None\n",
    "        self.backward_P = None\n",
    "    \n",
    "    # 前向算法\n",
    "    def forward(self, Q, V, A, B, O, PI):\n",
    "        # 状态序列的大小\n",
    "        N = len(Q)  \n",
    "        # 观测序列的大小\n",
    "        M = len(O)  \n",
    "        # 初始化前向概率alpha值\n",
    "        alphas = np.zeros((N, M))\n",
    "        # 时刻数=观测序列数\n",
    "        T = M  \n",
    "        # 遍历每一个时刻，计算前向概率alpha值\n",
    "        for t in range(T):  \n",
    "            # 得到序列对应的索引\n",
    "            indexOfO = V.index(O[t])\n",
    "            # 遍历状态序列\n",
    "            for i in range(N):\n",
    "                # 初始化alpha初值\n",
    "                if t == 0: \n",
    "                    # P176 公式(10.15)\n",
    "                    alphas[i][t] = PI[t][i] * B[i][indexOfO]  \n",
    "                    print('alpha1(%d) = p%db%db(o1) = %f' \n",
    "                          % (i+1, i, i, alphas[i][t]))\n",
    "                else:\n",
    "                    # P176 公式(10.16)\n",
    "                    alphas[i][t] = np.dot([alpha[t - 1] for alpha in alphas], \n",
    "                                          [a[i] for a in A]) * B[i][indexOfO]  \n",
    "                    print('alpha%d(%d) = [sigma alpha%d(i)ai%d]b%d(o%d) = %f' \n",
    "                          % (t+1, i+1, t - 1, i, i, t, alphas[i][t]))\n",
    "        # P176 公式(10.17)\n",
    "        self.forward_P = np.sum([alpha[M - 1] for alpha in alphas]) \n",
    "        self.alphas = alphas        \n",
    "        \n",
    "    # 后向算法\n",
    "    def backward(self, Q, V, A, B, O, PI):  \n",
    "        # 状态序列的大小\n",
    "        N = len(Q) \n",
    "        # 观测序列的大小\n",
    "        M = len(O) \n",
    "        # 初始化后向概率beta值，P178 公式(10.19)\n",
    "        betas = np.ones((N, M))  \n",
    "        # \n",
    "        for i in range(N):\n",
    "            print('beta%d(%d) = 1' % (M, i+1))\n",
    "        # 对观测序列逆向遍历\n",
    "        for t in range(M - 2, -1, -1):\n",
    "            # 得到序列对应的索引\n",
    "            indexOfO = V.index(O[t + 1])  \n",
    "             # 遍历状态序列\n",
    "            for i in range(N):\n",
    "                # P178 公式(10.20)\n",
    "                betas[i][t] = np.dot(np.multiply(A[i], [b[indexOfO] for b in B]), \n",
    "                                     [beta[t + 1] for beta in betas])\n",
    "                realT = t + 1\n",
    "                realI = i + 1\n",
    "                print('beta%d(%d) = sigma[a%djbj(o%d)beta%d(j)] = (' \n",
    "                      % (realT, realI, realI, realT + 1, realT + 1), end='')\n",
    "                for j in range(N):\n",
    "                    print(\"%.2f * %.2f * %.2f + \" \n",
    "                          % (A[i][j], B[j][indexOfO], betas[j][t + 1]), end='')\n",
    "                print(\"0) = %.3f\" % betas[i][t])\n",
    "        # 取出第一个值\n",
    "        indexOfO = V.index(O[0])\n",
    "        self.betas = betas\n",
    "        # P178 公式(10.21)\n",
    "        P = np.dot(np.multiply(PI, [b[indexOfO] for b in B]), \n",
    "                   [beta[0] for beta in betas])\n",
    "        self.backward_P = P\n",
    "        print(\"P(O|lambda) = \", end=\"\")\n",
    "        for i in range(N):\n",
    "            print(\"%.1f * %.1f * %.5f + \" \n",
    "                  % (PI[0][i], B[i][indexOfO], betas[i][0]), end=\"\")\n",
    "        print(\"0 = %f\" % P)\n",
    "    \n",
    "    # 维特比算法\n",
    "    def viterbi(self, Q, V, A, B, O, PI):\n",
    "        # 状态序列的大小\n",
    "        N = len(Q)  \n",
    "        # 观测序列的大小\n",
    "        M = len(O)  \n",
    "        # 初始化daltas\n",
    "        deltas = np.zeros((N, M))\n",
    "        # 初始化psis\n",
    "        psis = np.zeros((N, M))\n",
    "        # 初始化最优路径矩阵，该矩阵维度与观测序列维度相同\n",
    "        I = np.zeros((1, M))\n",
    "        # 遍历观测序列\n",
    "        for t in range(M):\n",
    "            # 递推从t=2开始\n",
    "            realT = t+1\n",
    "            # 得到序列对应的索引\n",
    "            indexOfO = V.index(O[t]) \n",
    "            for i in range(N):\n",
    "                realI = i+1\n",
    "                if t == 0:\n",
    "                    # P185 算法10.5 步骤(1)\n",
    "                    deltas[i][t] = PI[0][i] * B[i][indexOfO]\n",
    "                    psis[i][t] = 0\n",
    "                    print('delta1(%d) = pi%d * b%d(o1) = %.2f * %.2f = %.2f'\n",
    "                          %(realI, realI, realI, PI[0][i], B[i][indexOfO], deltas[i][t]))\n",
    "                    print('psis1(%d) = 0' % (realI))\n",
    "                else:\n",
    "                    # # P185 算法10.5 步骤(2)\n",
    "                    deltas[i][t] = np.max(np.multiply([delta[t-1] for delta in deltas], \n",
    "                                                      [a[i] for a in A])) * B[i][indexOfO]\n",
    "                    print('delta%d(%d) = max[delta%d(j)aj%d]b%d(o%d) = %.2f * %.2f = %.5f'\n",
    "                          %(realT, realI, realT-1, realI, realI, realT, \n",
    "                            np.max(np.multiply([delta[t-1] for delta in deltas], \n",
    "                                               [a[i] for a in A])), \n",
    "                            B[i][indexOfO], deltas[i][t]))\n",
    "                    psis[i][t] = np.argmax(np.multiply([delta[t-1] for delta in deltas], \n",
    "                                                       [a[i] for a in A]))\n",
    "                    print('psis%d(%d) = argmax[delta%d(j)aj%d] = %d' \n",
    "                          % (realT, realI, realT-1, realI, psis[i][t]))\n",
    "        #print(deltas)\n",
    "        #print(psis)\n",
    "        # 得到最优路径的终结点\n",
    "        I[0][M-1] = np.argmax([delta[M-1] for delta in deltas])\n",
    "        print('i%d = argmax[deltaT(i)] = %d' % (M, I[0][M-1]+1))\n",
    "        # 递归由后向前得到其他结点\n",
    "        for t in range(M-2, -1, -1):\n",
    "            I[0][t] = psis[int(I[0][t+1])][t+1]\n",
    "            print('i%d = psis%d(i%d) = %d' % (t+1, t+2, t+2, I[0][t]+1))\n",
    "        # 输出最优路径\n",
    "        print('最优路径是：',\"->\".join([str(int(i+1)) for i in I[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta4(1) = 1\n",
      "beta4(2) = 1\n",
      "beta4(3) = 1\n",
      "beta3(1) = sigma[a1jbj(o4)beta4(j)] = (0.50 * 0.50 * 1.00 + 0.20 * 0.60 * 1.00 + 0.30 * 0.30 * 1.00 + 0) = 0.460\n",
      "beta3(2) = sigma[a2jbj(o4)beta4(j)] = (0.30 * 0.50 * 1.00 + 0.50 * 0.60 * 1.00 + 0.20 * 0.30 * 1.00 + 0) = 0.510\n",
      "beta3(3) = sigma[a3jbj(o4)beta4(j)] = (0.20 * 0.50 * 1.00 + 0.30 * 0.60 * 1.00 + 0.50 * 0.30 * 1.00 + 0) = 0.430\n",
      "beta2(1) = sigma[a1jbj(o3)beta3(j)] = (0.50 * 0.50 * 0.46 + 0.20 * 0.40 * 0.51 + 0.30 * 0.70 * 0.43 + 0) = 0.246\n",
      "beta2(2) = sigma[a2jbj(o3)beta3(j)] = (0.30 * 0.50 * 0.46 + 0.50 * 0.40 * 0.51 + 0.20 * 0.70 * 0.43 + 0) = 0.231\n",
      "beta2(3) = sigma[a3jbj(o3)beta3(j)] = (0.20 * 0.50 * 0.46 + 0.30 * 0.40 * 0.51 + 0.50 * 0.70 * 0.43 + 0) = 0.258\n",
      "beta1(1) = sigma[a1jbj(o2)beta2(j)] = (0.50 * 0.50 * 0.25 + 0.20 * 0.60 * 0.23 + 0.30 * 0.30 * 0.26 + 0) = 0.112\n",
      "beta1(2) = sigma[a2jbj(o2)beta2(j)] = (0.30 * 0.50 * 0.25 + 0.50 * 0.60 * 0.23 + 0.20 * 0.30 * 0.26 + 0) = 0.122\n",
      "beta1(3) = sigma[a3jbj(o2)beta2(j)] = (0.20 * 0.50 * 0.25 + 0.30 * 0.60 * 0.23 + 0.50 * 0.30 * 0.26 + 0) = 0.105\n",
      "P(O|lambda) = 0.2 * 0.5 * 0.11246 + 0.4 * 0.4 * 0.12174 + 0.4 * 0.7 * 0.10488 + 0 = 0.060091\n"
     ]
    }
   ],
   "source": [
    "Q = [1, 2, 3]\n",
    "V = ['红', '白']\n",
    "A = [[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]]\n",
    "B = [[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]]\n",
    "O = ['红', '白', '红', '白'] \n",
    "PI = [[0.2, 0.4, 0.4]]\n",
    "\n",
    "HMM = HiddenMarkov()\n",
    "HMM.backward(Q, V, A, B, O, PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可得$P(O|\\lambda) = 0.060091$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题10.2\n",
    "\n",
    "&emsp;&emsp;给定盒子和球组成的隐马尔可夫模型$\\lambda=(A,B,\\pi)$，其中，$$A=\\left[\\begin{array}{ccc}0.5&0.1&0.4\\\\0.3&0.5&0.2\\\\0.2&0.2&0.6\\end{array}\\right], \\quad B=\\left[\\begin{array}{cc}0.5&0.5\\\\0.4&0.6\\\\0.7&0.3\\end{array}\\right], \\quad \\pi=(0.2,0.3,0.5)^T$$设$T=8,O=(红,白,红,红,白,红,白,白)$，试用前向后向概率计算$P(i_4=q_3|O,\\lambda)$\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha1(1) = p0b0b(o1) = 0.100000\n",
      "alpha1(2) = p1b1b(o1) = 0.120000\n",
      "alpha1(3) = p2b2b(o1) = 0.350000\n",
      "alpha2(1) = [sigma alpha0(i)ai0]b0(o1) = 0.078000\n",
      "alpha2(2) = [sigma alpha0(i)ai1]b1(o1) = 0.084000\n",
      "alpha2(3) = [sigma alpha0(i)ai2]b2(o1) = 0.082200\n",
      "alpha3(1) = [sigma alpha1(i)ai0]b0(o2) = 0.040320\n",
      "alpha3(2) = [sigma alpha1(i)ai1]b1(o2) = 0.026496\n",
      "alpha3(3) = [sigma alpha1(i)ai2]b2(o2) = 0.068124\n",
      "alpha4(1) = [sigma alpha2(i)ai0]b0(o3) = 0.020867\n",
      "alpha4(2) = [sigma alpha2(i)ai1]b1(o3) = 0.012362\n",
      "alpha4(3) = [sigma alpha2(i)ai2]b2(o3) = 0.043611\n",
      "alpha5(1) = [sigma alpha3(i)ai0]b0(o4) = 0.011432\n",
      "alpha5(2) = [sigma alpha3(i)ai1]b1(o4) = 0.010194\n",
      "alpha5(3) = [sigma alpha3(i)ai2]b2(o4) = 0.011096\n",
      "alpha6(1) = [sigma alpha4(i)ai0]b0(o5) = 0.005497\n",
      "alpha6(2) = [sigma alpha4(i)ai1]b1(o5) = 0.003384\n",
      "alpha6(3) = [sigma alpha4(i)ai2]b2(o5) = 0.009288\n",
      "alpha7(1) = [sigma alpha5(i)ai0]b0(o6) = 0.002811\n",
      "alpha7(2) = [sigma alpha5(i)ai1]b1(o6) = 0.002460\n",
      "alpha7(3) = [sigma alpha5(i)ai2]b2(o6) = 0.002535\n",
      "alpha8(1) = [sigma alpha6(i)ai0]b0(o7) = 0.001325\n",
      "alpha8(2) = [sigma alpha6(i)ai1]b1(o7) = 0.001211\n",
      "alpha8(3) = [sigma alpha6(i)ai2]b2(o7) = 0.000941\n",
      "beta8(1) = 1\n",
      "beta8(2) = 1\n",
      "beta8(3) = 1\n",
      "beta7(1) = sigma[a1jbj(o8)beta8(j)] = (0.50 * 0.50 * 1.00 + 0.10 * 0.60 * 1.00 + 0.40 * 0.30 * 1.00 + 0) = 0.430\n",
      "beta7(2) = sigma[a2jbj(o8)beta8(j)] = (0.30 * 0.50 * 1.00 + 0.50 * 0.60 * 1.00 + 0.20 * 0.30 * 1.00 + 0) = 0.510\n",
      "beta7(3) = sigma[a3jbj(o8)beta8(j)] = (0.20 * 0.50 * 1.00 + 0.20 * 0.60 * 1.00 + 0.60 * 0.30 * 1.00 + 0) = 0.400\n",
      "beta6(1) = sigma[a1jbj(o7)beta7(j)] = (0.50 * 0.50 * 0.43 + 0.10 * 0.60 * 0.51 + 0.40 * 0.30 * 0.40 + 0) = 0.186\n",
      "beta6(2) = sigma[a2jbj(o7)beta7(j)] = (0.30 * 0.50 * 0.43 + 0.50 * 0.60 * 0.51 + 0.20 * 0.30 * 0.40 + 0) = 0.241\n",
      "beta6(3) = sigma[a3jbj(o7)beta7(j)] = (0.20 * 0.50 * 0.43 + 0.20 * 0.60 * 0.51 + 0.60 * 0.30 * 0.40 + 0) = 0.176\n",
      "beta5(1) = sigma[a1jbj(o6)beta6(j)] = (0.50 * 0.50 * 0.19 + 0.10 * 0.40 * 0.24 + 0.40 * 0.70 * 0.18 + 0) = 0.106\n",
      "beta5(2) = sigma[a2jbj(o6)beta6(j)] = (0.30 * 0.50 * 0.19 + 0.50 * 0.40 * 0.24 + 0.20 * 0.70 * 0.18 + 0) = 0.101\n",
      "beta5(3) = sigma[a3jbj(o6)beta6(j)] = (0.20 * 0.50 * 0.19 + 0.20 * 0.40 * 0.24 + 0.60 * 0.70 * 0.18 + 0) = 0.112\n",
      "beta4(1) = sigma[a1jbj(o5)beta5(j)] = (0.50 * 0.50 * 0.11 + 0.10 * 0.60 * 0.10 + 0.40 * 0.30 * 0.11 + 0) = 0.046\n",
      "beta4(2) = sigma[a2jbj(o5)beta5(j)] = (0.30 * 0.50 * 0.11 + 0.50 * 0.60 * 0.10 + 0.20 * 0.30 * 0.11 + 0) = 0.053\n",
      "beta4(3) = sigma[a3jbj(o5)beta5(j)] = (0.20 * 0.50 * 0.11 + 0.20 * 0.60 * 0.10 + 0.60 * 0.30 * 0.11 + 0) = 0.043\n",
      "beta3(1) = sigma[a1jbj(o4)beta4(j)] = (0.50 * 0.50 * 0.05 + 0.10 * 0.40 * 0.05 + 0.40 * 0.70 * 0.04 + 0) = 0.026\n",
      "beta3(2) = sigma[a2jbj(o4)beta4(j)] = (0.30 * 0.50 * 0.05 + 0.50 * 0.40 * 0.05 + 0.20 * 0.70 * 0.04 + 0) = 0.023\n",
      "beta3(3) = sigma[a3jbj(o4)beta4(j)] = (0.20 * 0.50 * 0.05 + 0.20 * 0.40 * 0.05 + 0.60 * 0.70 * 0.04 + 0) = 0.027\n",
      "beta2(1) = sigma[a1jbj(o3)beta3(j)] = (0.50 * 0.50 * 0.03 + 0.10 * 0.40 * 0.02 + 0.40 * 0.70 * 0.03 + 0) = 0.015\n",
      "beta2(2) = sigma[a2jbj(o3)beta3(j)] = (0.30 * 0.50 * 0.03 + 0.50 * 0.40 * 0.02 + 0.20 * 0.70 * 0.03 + 0) = 0.012\n",
      "beta2(3) = sigma[a3jbj(o3)beta3(j)] = (0.20 * 0.50 * 0.03 + 0.20 * 0.40 * 0.02 + 0.60 * 0.70 * 0.03 + 0) = 0.016\n",
      "beta1(1) = sigma[a1jbj(o2)beta2(j)] = (0.50 * 0.50 * 0.01 + 0.10 * 0.60 * 0.01 + 0.40 * 0.30 * 0.02 + 0) = 0.006\n",
      "beta1(2) = sigma[a2jbj(o2)beta2(j)] = (0.30 * 0.50 * 0.01 + 0.50 * 0.60 * 0.01 + 0.20 * 0.30 * 0.02 + 0) = 0.007\n",
      "beta1(3) = sigma[a3jbj(o2)beta2(j)] = (0.20 * 0.50 * 0.01 + 0.20 * 0.60 * 0.01 + 0.60 * 0.30 * 0.02 + 0) = 0.006\n",
      "P(O|lambda) = 0.2 * 0.5 * 0.00633 + 0.3 * 0.4 * 0.00685 + 0.5 * 0.7 * 0.00578 + 0 = 0.003477\n"
     ]
    }
   ],
   "source": [
    "Q = [1, 2, 3]\n",
    "V = ['红', '白']\n",
    "A = [[0.5, 0.1, 0.4], [0.3, 0.5, 0.2], [0.2, 0.2, 0.6]]\n",
    "B = [[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]]\n",
    "O = ['红', '白', '红', '红', '白', '红', '白', '白']\n",
    "PI = [[0.2, 0.3, 0.5]]\n",
    "\n",
    "HMM = HiddenMarkov()\n",
    "HMM.forward(Q, V, A, B, O, PI)\n",
    "HMM.backward(Q, V, A, B, O, PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可知，$\\displaystyle P(i_4=q_3|O,\\lambda)=\\frac{P(i_4=q_3,O|\\lambda)}{P(O|\\lambda)}=\\frac{\\alpha_4(3)\\beta_4(3)}{P(O|\\lambda)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha4(3)= 0.043611119999999996\n",
      "beta4(3)= 0.04280618\n",
      "P(O|lambda)= 0.0034767094492824\n",
      "P(i4=q3|O,lambda) = 0.5369518160647322\n"
     ]
    }
   ],
   "source": [
    "print(\"alpha4(3)=\", HMM.alphas[3-1][4-1])\n",
    "print(\"beta4(3)=\", HMM.betas[3-1][4-1])\n",
    "print(\"P(O|lambda)=\", HMM.backward_P[0])\n",
    "result = (HMM.alphas[3-1][4-1] * HMM.betas[3-1][4-1]) / HMM.backward_P[0]\n",
    "print(\"P(i4=q3|O,lambda) =\",result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题10.3\n",
    "\n",
    "&emsp;&emsp;在习题10.1中，试用维特比算法求最优路径$I^*=(i_1^*,i_2^*,i_3^*,i_4^*)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta1(1) = pi1 * b1(o1) = 0.20 * 0.50 = 0.10\n",
      "psis1(1) = 0\n",
      "delta1(2) = pi2 * b2(o1) = 0.40 * 0.40 = 0.16\n",
      "psis1(2) = 0\n",
      "delta1(3) = pi3 * b3(o1) = 0.40 * 0.70 = 0.28\n",
      "psis1(3) = 0\n",
      "delta2(1) = max[delta1(j)aj1]b1(o2) = 0.06 * 0.50 = 0.02800\n",
      "psis2(1) = argmax[delta1(j)aj1] = 2\n",
      "delta2(2) = max[delta1(j)aj2]b2(o2) = 0.08 * 0.60 = 0.05040\n",
      "psis2(2) = argmax[delta1(j)aj2] = 2\n",
      "delta2(3) = max[delta1(j)aj3]b3(o2) = 0.14 * 0.30 = 0.04200\n",
      "psis2(3) = argmax[delta1(j)aj3] = 2\n",
      "delta3(1) = max[delta2(j)aj1]b1(o3) = 0.02 * 0.50 = 0.00756\n",
      "psis3(1) = argmax[delta2(j)aj1] = 1\n",
      "delta3(2) = max[delta2(j)aj2]b2(o3) = 0.03 * 0.40 = 0.01008\n",
      "psis3(2) = argmax[delta2(j)aj2] = 1\n",
      "delta3(3) = max[delta2(j)aj3]b3(o3) = 0.02 * 0.70 = 0.01470\n",
      "psis3(3) = argmax[delta2(j)aj3] = 2\n",
      "delta4(1) = max[delta3(j)aj1]b1(o4) = 0.00 * 0.50 = 0.00189\n",
      "psis4(1) = argmax[delta3(j)aj1] = 0\n",
      "delta4(2) = max[delta3(j)aj2]b2(o4) = 0.01 * 0.60 = 0.00302\n",
      "psis4(2) = argmax[delta3(j)aj2] = 1\n",
      "delta4(3) = max[delta3(j)aj3]b3(o4) = 0.01 * 0.30 = 0.00220\n",
      "psis4(3) = argmax[delta3(j)aj3] = 2\n",
      "i4 = argmax[deltaT(i)] = 2\n",
      "i3 = psis4(i4) = 2\n",
      "i2 = psis3(i3) = 2\n",
      "i1 = psis2(i2) = 3\n",
      "最优路径是： 3->2->2->2\n"
     ]
    }
   ],
   "source": [
    "Q = [1, 2, 3]\n",
    "V = ['红', '白']\n",
    "A = [[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]]\n",
    "B = [[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]]\n",
    "O = ['红', '白', '红', '白'] \n",
    "PI = [[0.2, 0.4, 0.4]]\n",
    "\n",
    "HMM = HiddenMarkov()\n",
    "HMM.viterbi(Q, V, A, B, O, PI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题10.4\n",
    "&emsp;&emsp;试用前向概率和后向概率推导$$P(O|\\lambda)=\\sum_{i=1}^N\\sum_{j=1}^N\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j),\\quad t=1,2,\\cdots,T-1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "$$\\begin{aligned}\n",
    "P(O|\\lambda)\n",
    "&= P(o_1,o_2,...,o_T|\\lambda) \\\\\n",
    "&= \\sum_{i=1}^N P(o_1,..,o_t,i_t=q_i|\\lambda) P(o_{t+1},..,o_T|i_t=q_i,\\lambda) \\\\\n",
    "&= \\sum_{i=1}^N \\sum_{j=1}^N P(o_1,..,o_t,i_t=q_i|\\lambda) P(o_{t+1},i_{t+1}=q_j|i_t=q_i,\\lambda)P(o_{t+2},..,o_T|i_{t+1}=q_j,\\lambda) \\\\\n",
    "&= \\sum_{i=1}^N \\sum_{j=1}^N [P(o_1,..,o_t,i_t=q_i|\\lambda) P(o_{t+1}|i_{t+1}=q_j,\\lambda) P(i_{t+1}=q_j|i_t=q_i,\\lambda) \\\\\n",
    "& \\quad \\quad \\quad \\quad P(o_{t+2},..,o_T|i_{t+1}=q_j,\\lambda)] \\\\\n",
    "&= \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_t(i) a_{ij} b_j(o_{t+1}) \\beta_{t+1}(j),{\\quad}t=1,2,...,T-1\n",
    "\\end{aligned}$$\n",
    "命题得证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题10.5\n",
    "\n",
    "&emsp;&emsp;比较维特比算法中变量$\\delta$的计算和前向算法中变量$\\alpha$的计算的主要区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**前向算法：**  \n",
    "1. 初值$$\\alpha_1(i)=\\pi_ib_i(o_i),i=1,2,\\cdots,N$$\n",
    "2. 递推，对$t=1,2,\\cdots,T-1$：$$\\alpha_{t+1}(i)=\\left[\\sum_{j=1}^N \\alpha_t(j) a_{ji} \\right]b_i(o_{t+1})，i=1,2,\\cdots,N$$\n",
    "\n",
    "**维特比算法：**  \n",
    "1. 初始化$$\\delta_1(i)=\\pi_ib_i(o_1),i=1,2,\\cdots,N$$\n",
    "2. 递推，对$t=2,3,\\cdots,T$$$\\delta_t(i)=\\max_{1 \\leqslant j \\leqslant N} [\\delta_{t-1}(j)a_{ji}]b_i(o_t), i=1,2,\\cdots,N$$  \n",
    "\n",
    "&emsp;&emsp;由上面算法可知，计算变量$\\alpha$的时候直接对上个的结果进行数值计算，而计算变量$\\delta$需要在上个结果计算的基础上选择最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 第11章条件随机场-习题\n",
    "\n",
    "### 习题11.1\n",
    "&emsp;&emsp;写出图11.3中无向图描述的概率图模型的因子分解式。\n",
    "<br/><center>\n",
    "<img style=\"border-radius: 0.3125em;box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" src=\"../images/11-1-Maximal-Clique.png\"><br><div style=\"color:orange; border-bottom: 1px solid #d9d9d9;display: inline-block;color: #000;padding: 2px;\">图11.3 无向图的团和最大团</div></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "&emsp;&emsp;图11.3表示由4个结点组成的无向图。图中由2个结点组成的团有5个：$\\{Y_1,Y_2\\},\\{Y_2,Y_3\\},\\{Y_3,Y_4\\},\\{Y_4,Y_2\\}$和$\\{Y_1,Y_3\\}$，有2个最大团：$\\{Y_1,Y_2,Y_3\\}$和$\\{Y_2,Y_3,Y_4\\}$，而$\\{Y_1,Y_2,Y_3,Y_4\\}$不是一个团，因为$Y_1$和$Y_4$没有边连接。  \n",
    "&emsp;&emsp;根据概率图模型的因子分解定义：将概率无向图模型的联合概率分布表示为其最大团上的随机变量的函数的乘积形式的操作。公式在书中(11.5)，(11.6)。  \n",
    "$$P(Y)=\\frac{\\Psi_{(1,2,3)}(Y_{(1,2,3)})\\cdot\\Psi_{(2,3,4)}(Y_{(2,3,4)})}{\\displaystyle \\sum_Y \\left[ \\Psi_{(1,2,3)}(Y_{(1,2,3)})\\cdot\\Psi_{(2,3,4)}(Y_{(2,3,4)})\\right]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题11.2\n",
    "\n",
    "&emsp;&emsp;证明$Z(x)=a_n^T(x) \\cdot \\boldsymbol{1} = \\boldsymbol{1}^T\\cdot\\beta_1(x)$，其中$\\boldsymbol{1}$是元素均为1的$m$维列向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "**第1步：**证明$Z(x)=a_n^T(x) \\cdot \\boldsymbol{1}$  \n",
    "根据条件随机场的矩阵形式：$$(M_{n+1}(x))_{i,j}=\\begin{cases}\n",
    "1,&j=\\text{stop}\\\\\n",
    "0,&\\text{otherwise}\n",
    "\\end{cases}$$根据前向向量的定义：$$\\alpha_0(y|x)=\\begin{cases}\n",
    "1,&y=\\text{start} \\\\\n",
    "0,&\\text{otherwise}\n",
    "\\end{cases}$$  \n",
    "$\\begin{aligned}\n",
    "\\therefore Z_n(x) \n",
    "&= \\left(M_1(x)M_2(x){\\cdots}M_{n+1}(x)\\right)_{(\\text{start},\\text{stop})} \\\\\n",
    "&= \\alpha_0(x)^T M_1(x)M_2(x){\\cdots}M_n(x) \\cdot 1\\\\\n",
    "&=\\alpha_n(x)^T\\cdot \\boldsymbol{1}\n",
    "\\end{aligned}$  \n",
    "\n",
    "-----\n",
    "\n",
    "**第2步：**证明$Z(x)=\\boldsymbol{1}^T \\cdot \\beta_1(x)$  \n",
    "根据条件随机场的矩阵形式：$$(M_{n+1}(x))_{i,j}=\\begin{cases}\n",
    "1,&j=\\text{stop}\\\\\n",
    "0,&\\text{otherwise}\n",
    "\\end{cases}$$根据后向向量定义：$$\\beta_{n+1}(y_{n+1}|x)=\n",
    "\\begin{cases}\n",
    "1,& y_{n+1}=\\text{stop} \\\\\n",
    "0,& \\text{otherwise}\n",
    "\\end{cases}$$  \n",
    "$\\begin{aligned}\n",
    "\\therefore Z_n(x)\n",
    "&= (M_1(x)M_2(x) \\cdots M_{n+1}(x))_{(\\text{start},\\text{stop})} \\\\\n",
    "&= (M_1(x)M_2(x) \\cdots M_n(x) \\beta_{n+1}(x))_{\\text{start}} \\\\\n",
    "&=(\\beta_1(x))_{\\text{start}} \\\\\n",
    "&=\\boldsymbol{1}^T \\cdot \\beta_1(x)\n",
    "\\end{aligned}$  \n",
    "综上所述：$Z(x)=a_n^T(x) \\cdot \\boldsymbol{1} = \\boldsymbol{1}^T \\cdot \\beta_1(x)$，命题得证。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题11.3\n",
    "&emsp;&emsp;写出条件随机场模型学习的梯度下降法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**  \n",
    "条件随机场的对数极大似然函数为：$$L(w)=\\sum^N_{j=1} \\sum^K_{k=1} w_k f_k(y_j,x_j)-\\sum^N_{j=1} \\log{Z_w(x_j)}$$梯度下降算法的目标函数是$f(w)=-L(w)$  \n",
    "目标函数的梯度为：$$g(w)=\\nabla{f(w^{(k)})}=\\left(\\frac{\\partial{f(w)}}{\\partial{w_1}},\\frac{\\partial{f(w)}}{\\partial{w_2}},\\cdots,\\frac{\\partial{f(w)}}{\\partial{w_k}}\\right)$$其中$$\\begin{aligned}\n",
    "\\frac{\\partial{f(w)}}{\\partial{w_i}}\n",
    "&= -\\sum^N_{j=1} w_i f_i(y_j,x_j) + \\sum^N_{j=1} \\frac{1}{Z_w(x_j)} \\cdot \\frac{\\partial{Z_w(x_j)}}{\\partial{w_i}}\\\\\n",
    "&= -\\sum^N_{j=1}w_if_i(y_j,x_j)+\\sum^N_{j=1}\\frac{1}{Z_w(x_j)}\\sum_y(\\exp{\\sum^K_{k=1}w_kf_k(y,x_j))}w_if_i(y,x_j)\n",
    "\\end{aligned}$$  \n",
    "根据梯度下降算法：  \n",
    "1. 取初始值$w^{(0)} \\in \\mathbf{R}^n$，置$k=0$  \n",
    "2. 计算$f(w^{(k)})$  \n",
    "3. 计算梯度$g_k=g(w^{(k)})$，当$\\|g_k\\|<\\varepsilon$时，停止迭代，令$w^*=w^{(k)}$；否则令$p_k=-g(w^{(k)})$，求$\\lambda_k$，使$$\n",
    "f(w^{(k)}+\\lambda_k p_k)=\\min_{\\lambda \\geqslant 0}{f(w^{(k)}+\\lambda p_k)}$$  \n",
    "4. 置$w^{(k+1)}=w^{(k)}+\\lambda_k p_k$，计算$f(w^{(k+1)})$  \n",
    "当$\\|f(w^{(k+1)})-f(w^{(k)})\\| < \\epsilon$或$\\|w^{(k+1)}-w^{(k)}\\| < \\epsilon$时，停止迭代，令$w^*=w^{(k+1)}$  \n",
    "5. 否则，置$k=k+1$，转(3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题11.4\n",
    "\n",
    "参考图11.6的状态路径图，假设随机矩阵$M_1(x),M_2(x),M_3(x),M_4(x)$分别是\n",
    "$$M_1(x)=\\begin{bmatrix}0&0\\\\0.5&0.5\\end{bmatrix} ,\n",
    "M_2(x)=\\begin{bmatrix}0.3&0.7\\\\0.7&0.3\\end{bmatrix}$$\n",
    "$$\n",
    "M_3(x)=\\begin{bmatrix}0.5&0.5\\\\0.6&0.4\\end{bmatrix},\n",
    "M_4(x)=\\begin{bmatrix}0&1\\\\0&1\\end{bmatrix}$$\n",
    "求以$start=2$为起点$stop=2$为终点的所有路径的状态序列$y$的概率及概率最大的状态序列。\n",
    "\n",
    "**解答：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 0], [0.5, 0.5]], [[0.3, 0.7], [0.7, 0.3]], [[0.5, 0.5], [0.6, 0.4]], [[0, 1], [0, 1]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 创建随机矩阵\n",
    "M1 = [[0,0],[0.5,0.5]] \n",
    "M2 = [[0.3, 0.7], [0.7,0.3]]\n",
    "M3 = [[0.5, 0.5], [0.6, 0.4]]\n",
    "M4 = [[0, 1], [0, 1]]\n",
    "M = [M1, M2, M3, M4]\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2, 1, 1, 1, 2]), array([2, 1, 1, 2, 2]), array([2, 1, 2, 1, 2]), array([2, 1, 2, 2, 2]), array([2, 2, 1, 1, 2]), array([2, 2, 1, 2, 2]), array([2, 2, 2, 1, 2]), array([2, 2, 2, 2, 2])]\n"
     ]
    }
   ],
   "source": [
    "# 生成路径\n",
    "path = [2]\n",
    "for i in range(1,4):\n",
    "    paths = []\n",
    "    for _, r in enumerate(path):\n",
    "        temp = np.transpose(r)\n",
    "        paths.append(np.append(temp, 1))\n",
    "        paths.append(np.append(temp, 2))\n",
    "    path = paths.copy()\n",
    "\n",
    "path = [np.append(r, 2) for _, r in enumerate(path)]\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([2, 1, 2, 1, 2], 0.21), ([2, 2, 1, 1, 2], 0.175), ([2, 2, 1, 2, 2], 0.175), ([2, 1, 2, 2, 2], 0.13999999999999999), ([2, 2, 2, 1, 2], 0.09), ([2, 1, 1, 1, 2], 0.075), ([2, 1, 1, 2, 2], 0.075), ([2, 2, 2, 2, 2], 0.06)]\n"
     ]
    }
   ],
   "source": [
    "# 计算概率\n",
    "\n",
    "pr = []\n",
    "for _, row in enumerate(path):\n",
    "    p = 1\n",
    "    for i in range(len(row)-1):\n",
    "        a = row[i]\n",
    "        b = row[i+1]\n",
    "        p *= M[i][a-1][b-1]\n",
    "    pr.append((row.tolist(), p))\n",
    "pr = sorted(pr, key=lambda x : x[1], reverse=True)\n",
    "print(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "以start=2为起点stop=2为终点的所有路径的状态序列y的概率为：\n",
      "    路径为：2->1->2->1->2 概率为：0.21\n",
      "    路径为：2->2->1->1->2 概率为：0.175\n",
      "    路径为：2->2->1->2->2 概率为：0.175\n",
      "    路径为：2->1->2->2->2 概率为：0.13999999999999999\n",
      "    路径为：2->2->2->1->2 概率为：0.09\n",
      "    路径为：2->1->1->1->2 概率为：0.075\n",
      "    路径为：2->1->1->2->2 概率为：0.075\n",
      "    路径为：2->2->2->2->2 概率为：0.06\n",
      "概率[0.21]最大的状态序列为: 2->1->2->1->2\n"
     ]
    }
   ],
   "source": [
    "# 打印结果\n",
    "print(\"以start=2为起点stop=2为终点的所有路径的状态序列y的概率为：\")\n",
    "for path, p in pr:\n",
    "    print(\"    路径为：\" + \"->\".join([ str(x) for x in path]) ,end=\" \")\n",
    "    print(\"概率为：\" + str(p))\n",
    "print(\"概率[\" + str(pr[0][1]) +\"]最大的状态序列为:\",\n",
    "      \"->\".join([str(x) for x in pr[0][0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
